{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2d3b96",
   "metadata": {},
   "source": [
    "## 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fb4474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [5, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b7d4b4",
   "metadata": {},
   "source": [
    "## 데이터 세트 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e717bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../Integrated_data/all_dataset2.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d7be6-d7f0-463e-97f1-3ad6265940d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, dev_dataset = random_split(train_dataset, [int(len(train_dataset) * 0.83), int(len(train_dataset) * 0.17)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa120f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID 개수:  327\n",
      "Record 개수:  182\n"
     ]
    }
   ],
   "source": [
    "print(\"ID 개수: \",len(df['ID'].unique()))\n",
    "print(\"Record 개수: \", len(df[df['ID']=='#AAGQKY']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79239e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>collect_datetime</th>\n",
       "      <th>gender</th>\n",
       "      <th>grade</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>step_count</th>\n",
       "      <th>burned calory</th>\n",
       "      <th>eat_calory</th>\n",
       "      <th>Sleep_time</th>\n",
       "      <th>before_height</th>\n",
       "      <th>before_weight</th>\n",
       "      <th>before_waist</th>\n",
       "      <th>after_height</th>\n",
       "      <th>after_weight</th>\n",
       "      <th>after_waist</th>\n",
       "      <th>bmi</th>\n",
       "      <th>waist_bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#AAGQKY</td>\n",
       "      <td>2022-07-14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.15</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.877</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>-</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.612673</td>\n",
       "      <td>0.306081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#AAGQKY</td>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.15</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.877</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>-</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.612673</td>\n",
       "      <td>0.306081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#AAGQKY</td>\n",
       "      <td>2022-07-16</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.15</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.877</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>-</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.612673</td>\n",
       "      <td>0.306081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#AAGQKY</td>\n",
       "      <td>2022-07-17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.15</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.877</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>-</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.612673</td>\n",
       "      <td>0.306081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#AAGQKY</td>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.15</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.877</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>-</td>\n",
       "      <td>148.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.612673</td>\n",
       "      <td>0.306081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID collect_datetime  gender  grade  height  weight  step_count  \\\n",
       "0  #AAGQKY       2022-07-14     2.0    4.0   148.0   45.15        72.0   \n",
       "1  #AAGQKY       2022-07-15     2.0    4.0   148.0   45.15        72.0   \n",
       "2  #AAGQKY       2022-07-16     2.0    4.0   148.0   45.15        72.0   \n",
       "3  #AAGQKY       2022-07-17     2.0    4.0   148.0   45.15        72.0   \n",
       "4  #AAGQKY       2022-07-18     2.0    4.0   148.0   45.15        72.0   \n",
       "\n",
       "   burned calory  eat_calory  Sleep_time  before_height  before_weight  \\\n",
       "0          8.877      2000.0        12.0          148.0           45.3   \n",
       "1          8.877      2000.0        12.0          148.0           45.3   \n",
       "2          8.877      2000.0        12.0          148.0           45.3   \n",
       "3          8.877      2000.0        12.0          148.0           45.3   \n",
       "4          8.877      2000.0        12.0          148.0           45.3   \n",
       "\n",
       "  before_waist  after_height  after_weight  after_waist        bmi  waist_bmi  \n",
       "0            -         148.0          45.0          NaN  20.612673   0.306081  \n",
       "1            -         148.0          45.0          NaN  20.612673   0.306081  \n",
       "2            -         148.0          45.0          NaN  20.612673   0.306081  \n",
       "3            -         148.0          45.0          NaN  20.612673   0.306081  \n",
       "4            -         148.0          45.0          NaN  20.612673   0.306081  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244812f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_size = len(train_dataset)\n",
    "total_test_size = len(test_dataset)\n",
    "total_dev_size = len(dev_dataset)\n",
    "\n",
    "classes = 10\n",
    "input_dim = 784\n",
    "\n",
    "num_clients = 8\n",
    "rounds = 30\n",
    "batch_size = 128\n",
    "epochs_per_client = 3\n",
    "learning_rate = 2e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a945f077",
   "metadata": {},
   "source": [
    "## GPU 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18e0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader(DataLoader):\n",
    "        def __init__(self, dl, device):\n",
    "            self.dl = dl\n",
    "            self.device = device\n",
    "\n",
    "        def __iter__(self):\n",
    "            for batch in self.dl:\n",
    "                yield to_device(batch, self.device)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dl)\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f865d9",
   "metadata": {},
   "source": [
    "## 딥러닝 메인 모델정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8df62e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNNModel,self).__init__()\n",
    "        self.input_layer=nn.Linear(6,128)\n",
    "        self.hidden_layer1=nn.Linear(128, 256)\n",
    "        self.hidden_layer2=nn.Linear(256,128)\n",
    "        self.output_layer=nn.Linear(128,3)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.track_layers={'hidden_layer1':self.hidden_layer1,'hidden_layer2':self.hidden_layer2,'output_layer':self.output_layer}\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out=self.relu(self.input_layer(x))\n",
    "        out=self.relu(self.hidden_layer1(out))\n",
    "        \n",
    "    def get_track_layer(self):\n",
    "        return self.track_layers\n",
    "    \n",
    "    def apply_parameters(self, parameters_dict):\n",
    "        with torch.no_grad():\n",
    "            for layer_name in parameters_dict:\n",
    "                self.track_layer[layer_name].weight.data*=0 #track_layer[layer_name]의 가중치 값을 초기화 한다.\n",
    "                self.track_layer[layer_name].bias.data*=0   #track_layer[layer_name]의 bias 값을 초기화 한다. \n",
    "                self.track_layer[layer_name].weight.data=parameters_dict[layer_name]['weight']\n",
    "                self.track_layer[layer_name].bias.data=parameters_dict[layer_name]['bias']\n",
    "            \n",
    "    def get_parameters(self):\n",
    "        parameters_dict=dict()\n",
    "        for layer_name in self.track_layers:\n",
    "            parameters_dict[layer_name]={\n",
    "                'weight':self.track_layers[layer_name].weight.data,\n",
    "                'bias': self.track_layers[layer_name].bias.data\n",
    "            }\n",
    "        return parameters_dict\n",
    "    \n",
    "    def batch_accuracy(self,outputs,labels):\n",
    "        with torch.no_grad():\n",
    "            _, predictions=torch.max(outputs,dim=1)\n",
    "            return torch.tensor(torch.sum(predictions==labels).item()/len(predictions))\n",
    "          \n",
    "    def _process_batch(self, batch):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, labels)\n",
    "        accuracy = self.batch_accuracy(outputs, labels)\n",
    "        return (loss, accuracy)\n",
    "    \n",
    "    def fit(self, dataset, epochs,lr,batch_size=128,opt=torch.optim.SGD): # 학습시키는 함수 \n",
    "        dataloader=DeviceDataLoader(DataLoader(dataset, batchsize, shuffle=True), device)\n",
    "        optimizer=opt(self.parameters(),lr)\n",
    "        history=[]\n",
    "        for epoch in range(epochs):\n",
    "            losses=[]\n",
    "            accs=[]\n",
    "            for batch in dataloader:\n",
    "                loss,acc=self._process_batch(batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                loss.detach() # losses의 역전파를 멈추는 코드이다.\n",
    "                losses.append(loss)\n",
    "                accs.append(acc)\n",
    "            avg_loss=torch.stack(losses).mean().item()\n",
    "            avg_acc=torch.stack(accs).mean().item()\n",
    "            history.append((avg_loss,avg_acc))\n",
    "        return history\n",
    "    \n",
    "    def evaluate(self, dataset, batch_size=128):\n",
    "        dataloader=DeviceDataLoader(DataLoader(dataset,batch_size),device)\n",
    "        losses=[]\n",
    "        accs=[]\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                loss, acc=self._process_batch(batch)\n",
    "                losses.append(loss)\n",
    "                accs.append(acc)\n",
    "        avg_loss=torch.stack(losses).mean().item()\n",
    "        avg_acc=torch.stack(accs).mean.item()\n",
    "        return (avg_loss,avg_acc)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "113dde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, client_id, dataset):\n",
    "        self.client_id = client_id\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def get_dataset_size(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def get_client_id(self):\n",
    "        return self.client_id\n",
    "    \n",
    "    def train(self, parameters_dict):\n",
    "        net = to_device(FederatedNet(), device)\n",
    "        net.apply_parameters(parameters_dict)\n",
    "        train_history = net.fit(self.dataset, epochs_per_client, learning_rate, batch_size)\n",
    "        print('{}: Loss = {}, Accuracy = {}'.format(self.client_id, round(train_history[-1][0], 4), round(train_history[-1][1], 4)))\n",
    "        return net.get_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e30290d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a208eb94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_train_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18712\\1022360572.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexamples_per_client\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_train_size\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mnum_clients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m client_datasets = random_split(train_dataset, [min(i + examples_per_client, \n\u001b[0;32m      3\u001b[0m            total_train_size) - i for i in range(0, total_train_size, examples_per_client)])\n\u001b[0;32m      4\u001b[0m \u001b[0mclients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'client_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclient_datasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_clients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'total_train_size' is not defined"
     ]
    }
   ],
   "source": [
    "examples_per_client = total_train_size // num_clients\n",
    "client_datasets = random_split(train_dataset, [min(i + examples_per_client, \n",
    "           total_train_size) - i for i in range(0, total_train_size, examples_per_client)])\n",
    "clients = [Client('client_' + str(i), client_datasets[i]) for i in range(num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8726d301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708e6a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_net = to_device(FederatedNet(), device)\n",
    "history = []\n",
    "for i in range(rounds):\n",
    "    print('Start Round {} ...'.format(i + 1))\n",
    "    curr_parameters = global_net.get_parameters()\n",
    "    new_parameters = dict([(layer_name, {'weight': 0, 'bias': 0}) for layer_name in curr_parameters])\n",
    "    for client in clients:\n",
    "        client_parameters = client.train(curr_parameters)\n",
    "        fraction = client.get_dataset_size() / total_train_size\n",
    "        for layer_name in client_parameters:\n",
    "            new_parameters[layer_name]['weight'] += fraction * client_parameters[layer_name]['weight']\n",
    "            new_parameters[layer_name]['bias'] += fraction * client_parameters[layer_name]['bias']\n",
    "    global_net.apply_parameters(new_parameters)\n",
    "    \n",
    "    train_loss, train_acc = global_net.evaluate(train_dataset)\n",
    "    dev_loss, dev_acc = global_net.evaluate(dev_dataset)\n",
    "    print('After round {}, train_loss = {}, dev_loss = {}, dev_acc = {}\\n'.format(i + 1, round(train_loss, 4), \n",
    "            round(dev_loss, 4), round(dev_acc, 4)))\n",
    "    history.append((train_loss, dev_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42136180-22fc-47e1-ba0f-a8b2ec2ebb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i + 1 for i in range(len(history))], [history[i][0] for i in range(len(history))], color='r', label='train loss')\n",
    "plt.plot([i + 1 for i in range(len(history))], [history[i][1] for i in range(len(history))], color='b', label='dev loss')\n",
    "plt.legend()\n",
    "plt.title('Training history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63302016-4c88-4504-8428-175e7ac0b361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a85db2-73fc-4456-a77f-3cfadc0a0e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea21226-fb03-4a11-81ce-ed7e95a5d795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
