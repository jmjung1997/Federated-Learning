{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2391e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense,Dropout,Activation\n",
    "from tensorflow.python.keras import metrics\n",
    "from tensorflow.python import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7c1c5",
   "metadata": {},
   "source": [
    "# 파일읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e11779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('./modeling_data/result3.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7427da",
   "metadata": {},
   "source": [
    "# 데이터를 필요한 부분으로 X, Y 나눠 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67abaa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:7]\n",
    "y_origin=df['Label']\n",
    "# y=df['Label']\n",
    "y=pd.get_dummies(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22fc67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25755</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25756</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25757</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25758</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25759</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25760 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1     2    3    4    5      6\n",
       "0      45.0  72.0  0.0  0.0  0.0  148.0\n",
       "1      45.0  72.0  0.0  0.0  0.0  148.0\n",
       "2      45.0  72.0  0.0  0.0  0.0  148.0\n",
       "3      45.0  72.0  0.0  0.0  0.0  148.0\n",
       "4      45.0  72.0  0.0  0.0  0.0  148.0\n",
       "...     ...   ...  ...  ...  ...    ...\n",
       "25755  68.0   0.0  0.0  0.0  0.0  153.0\n",
       "25756  68.0   0.0  0.0  0.0  0.0  153.0\n",
       "25757  68.0   0.0  0.0  0.0  0.0  153.0\n",
       "25758  68.0   0.0  0.0  0.0  0.0  153.0\n",
       "25759  68.0   0.0  0.0  0.0  0.0  153.0\n",
       "\n",
       "[25760 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37bafc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4118207",
   "metadata": {},
   "source": [
    "# train, test, validation set 으로 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74280645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling\n",
    "# ms=MinMaxScaler()\n",
    "# X=ms.fit_transform(X)\n",
    "\n",
    "# 데이터 train, vali, test 6:2:2\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.30)\n",
    "\n",
    "train_x=train_x.to_numpy()\n",
    "test_x=test_x.to_numpy()\n",
    "train_y=train_y.to_numpy()\n",
    "test_y=test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06207ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c238ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트:  (18032, 6) (18032, 3)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (47679, 6) (47679, 3)\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=0)\n",
    "train_x_over,train_y_over = smote.fit_resample(train_x,train_y)\n",
    "\n",
    "# smote_test = SMOTE(random_state=0)\n",
    "# test_x,test_y = smote_test.fit_resample(test_x,test_y)\n",
    "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', train_x.shape, train_y.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', train_x_over.shape, train_y_over.shape)\n",
    "# print('SMOTE 적용 전 레이블 값 분포: \\n', pd.Series(train_y).value_counts())\n",
    "# print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(train_y_over).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbff9b7",
   "metadata": {},
   "source": [
    "# 모델\n",
    "\n",
    "## Deep Neural Network\n",
    "\n",
    "## Input Layer : None ,6\n",
    "\n",
    "## Hidden Layer : 128 - 256 - 128\n",
    "\n",
    "## optimizer : adam, loss : categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f916abcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "672/672 [==============================] - 2s 2ms/step - loss: 10.6325 - accuracy: 0.4710TA: 0s - loss: 30.602\n",
      "Epoch 2/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 2.5268 - accuracy: 0.5329: 0s - loss: 2.9014 - \n",
      "Epoch 3/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 1.5332 - accuracy: 0.5632: 0s - loss: 1.5982 - accuracy: \n",
      "Epoch 4/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 1.1123 - accuracy: 0.5856\n",
      "Epoch 5/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.9628 - accuracy: 0.6000\n",
      "Epoch 6/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.8512 - accuracy: 0.6210\n",
      "Epoch 7/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.8418 - accuracy: 0.6187\n",
      "Epoch 8/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7909 - accuracy: 0.6326\n",
      "Epoch 9/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.8155 - accuracy: 0.6181\n",
      "Epoch 10/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7903 - accuracy: 0.6335\n",
      "Epoch 11/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7769 - accuracy: 0.6340\n",
      "Epoch 12/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7935 - accuracy: 0.6257\n",
      "Epoch 13/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7718 - accuracy: 0.6296\n",
      "Epoch 14/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7697 - accuracy: 0.6385\n",
      "Epoch 15/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7774 - accuracy: 0.6316\n",
      "Epoch 16/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7883 - accuracy: 0.6242\n",
      "Epoch 17/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7743 - accuracy: 0.6347\n",
      "Epoch 18/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7691 - accuracy: 0.6441\n",
      "Epoch 19/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7532 - accuracy: 0.6463\n",
      "Epoch 20/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7493 - accuracy: 0.6498\n",
      "Epoch 21/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7233 - accuracy: 0.6741: 0s - loss: 0.7264 - accura\n",
      "Epoch 22/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7097 - accuracy: 0.6771\n",
      "Epoch 23/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7138 - accuracy: 0.6781: 0s - loss: 0.7138 - accuracy: 0.67\n",
      "Epoch 24/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.7051 - accuracy: 0.6817\n",
      "Epoch 25/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6945 - accuracy: 0.6882\n",
      "Epoch 26/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6915 - accuracy: 0.6910\n",
      "Epoch 27/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6908 - accuracy: 0.6906\n",
      "Epoch 28/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6974 - accuracy: 0.6875\n",
      "Epoch 29/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6750 - accuracy: 0.6997: 0s - loss: 0.6749 - accuracy: 0.69\n",
      "Epoch 30/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6690 - accuracy: 0.7007: 0s\n",
      "Epoch 31/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6670 - accuracy: 0.7026\n",
      "Epoch 32/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6579 - accuracy: 0.7058\n",
      "Epoch 33/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6544 - accuracy: 0.7089: 0s - loss: 0.6541 - accuracy: 0.70\n",
      "Epoch 34/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6548 - accuracy: 0.7077\n",
      "Epoch 35/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6413 - accuracy: 0.7148\n",
      "Epoch 36/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6379 - accuracy: 0.7164\n",
      "Epoch 37/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6306 - accuracy: 0.7204\n",
      "Epoch 38/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6333 - accuracy: 0.7195\n",
      "Epoch 39/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6298 - accuracy: 0.7219\n",
      "Epoch 40/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6223 - accuracy: 0.7276\n",
      "Epoch 41/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6171 - accuracy: 0.7309\n",
      "Epoch 42/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6148 - accuracy: 0.7324\n",
      "Epoch 43/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6101 - accuracy: 0.7359\n",
      "Epoch 44/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6116 - accuracy: 0.7367: 0s - loss: 0.6112 \n",
      "Epoch 45/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6080 - accuracy: 0.7349\n",
      "Epoch 46/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6046 - accuracy: 0.7394\n",
      "Epoch 47/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6066 - accuracy: 0.7361\n",
      "Epoch 48/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6003 - accuracy: 0.7389\n",
      "Epoch 49/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6001 - accuracy: 0.7406\n",
      "Epoch 50/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5959 - accuracy: 0.7437\n",
      "Epoch 51/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.7430\n",
      "Epoch 52/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.7451\n",
      "Epoch 53/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5883 - accuracy: 0.7466\n",
      "Epoch 54/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5862 - accuracy: 0.7491\n",
      "Epoch 55/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.7464\n",
      "Epoch 56/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5813 - accuracy: 0.7520\n",
      "Epoch 57/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5832 - accuracy: 0.7504\n",
      "Epoch 58/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5802 - accuracy: 0.7534\n",
      "Epoch 59/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5763 - accuracy: 0.7531\n",
      "Epoch 60/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5770 - accuracy: 0.7516\n",
      "Epoch 61/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5754 - accuracy: 0.7542\n",
      "Epoch 62/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5855 - accuracy: 0.7517\n",
      "Epoch 63/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5726 - accuracy: 0.7563\n",
      "Epoch 64/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5735 - accuracy: 0.7547\n",
      "Epoch 65/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5729 - accuracy: 0.7567\n",
      "Epoch 66/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5767 - accuracy: 0.7560\n",
      "Epoch 67/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5768 - accuracy: 0.7535\n",
      "Epoch 68/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.6063 - accuracy: 0.7443\n",
      "Epoch 69/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5631 - accuracy: 0.7601\n",
      "Epoch 70/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5722 - accuracy: 0.7541\n",
      "Epoch 71/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5593 - accuracy: 0.7608\n",
      "Epoch 72/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5619 - accuracy: 0.7607\n",
      "Epoch 73/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5615 - accuracy: 0.7588: 0s -\n",
      "Epoch 74/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5620 - accuracy: 0.7604\n",
      "Epoch 75/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5598 - accuracy: 0.7607\n",
      "Epoch 76/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5566 - accuracy: 0.7619\n",
      "Epoch 77/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5522 - accuracy: 0.7643\n",
      "Epoch 78/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5470 - accuracy: 0.7657\n",
      "Epoch 79/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7677\n",
      "Epoch 80/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.7631\n",
      "Epoch 81/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5478 - accuracy: 0.7664: 0s - loss: 0.5480 - accura\n",
      "Epoch 82/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5487 - accuracy: 0.7678\n",
      "Epoch 83/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5420 - accuracy: 0.7688: 0s - loss: 0\n",
      "Epoch 84/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7697\n",
      "Epoch 85/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7682\n",
      "Epoch 86/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7668\n",
      "Epoch 87/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.7704\n",
      "Epoch 88/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.7703\n",
      "Epoch 89/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5409 - accuracy: 0.7678\n",
      "Epoch 90/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7707\n",
      "Epoch 91/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7693\n",
      "Epoch 92/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5340 - accuracy: 0.7725\n",
      "Epoch 93/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5581 - accuracy: 0.7617\n",
      "Epoch 94/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5315 - accuracy: 0.7722\n",
      "Epoch 95/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5278 - accuracy: 0.7758\n",
      "Epoch 96/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.5319 - accuracy: 0.7738\n",
      "Epoch 97/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5279 - accuracy: 0.7735\n",
      "Epoch 98/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5224 - accuracy: 0.7770\n",
      "Epoch 99/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7712\n",
      "Epoch 100/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5247 - accuracy: 0.7765\n",
      "Epoch 101/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5242 - accuracy: 0.7763\n",
      "Epoch 102/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5215 - accuracy: 0.7790\n",
      "Epoch 103/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5236 - accuracy: 0.7767\n",
      "Epoch 104/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5180 - accuracy: 0.7803\n",
      "Epoch 105/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.5222 - accuracy: 0.7789\n",
      "Epoch 106/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7774\n",
      "Epoch 107/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5168 - accuracy: 0.7783\n",
      "Epoch 108/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5143 - accuracy: 0.7797\n",
      "Epoch 109/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5174 - accuracy: 0.7782\n",
      "Epoch 110/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5138 - accuracy: 0.7803\n",
      "Epoch 111/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5139 - accuracy: 0.7810\n",
      "Epoch 112/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5115 - accuracy: 0.7822\n",
      "Epoch 113/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5094 - accuracy: 0.7808\n",
      "Epoch 114/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5183 - accuracy: 0.7767\n",
      "Epoch 115/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5099 - accuracy: 0.7828\n",
      "Epoch 116/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5152 - accuracy: 0.7802\n",
      "Epoch 117/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5093 - accuracy: 0.7837\n",
      "Epoch 118/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5098 - accuracy: 0.7825: 0s - loss: 0.5112 - accuracy\n",
      "Epoch 119/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5156 - accuracy: 0.7781\n",
      "Epoch 120/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.5066 - accuracy: 0.7834\n",
      "Epoch 121/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5071 - accuracy: 0.7842\n",
      "Epoch 122/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5071 - accuracy: 0.7841\n",
      "Epoch 123/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5126 - accuracy: 0.7830\n",
      "Epoch 124/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5045 - accuracy: 0.7855\n",
      "Epoch 125/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.7879\n",
      "Epoch 126/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5033 - accuracy: 0.7853\n",
      "Epoch 127/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5109 - accuracy: 0.7839\n",
      "Epoch 128/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5015 - accuracy: 0.7870\n",
      "Epoch 129/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5040 - accuracy: 0.7860\n",
      "Epoch 130/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4952 - accuracy: 0.7892\n",
      "Epoch 131/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4971 - accuracy: 0.7885\n",
      "Epoch 132/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5020 - accuracy: 0.7866\n",
      "Epoch 133/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4952 - accuracy: 0.7884\n",
      "Epoch 134/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4999 - accuracy: 0.7867\n",
      "Epoch 135/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4949 - accuracy: 0.7892\n",
      "Epoch 136/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4945 - accuracy: 0.7890\n",
      "Epoch 137/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4985 - accuracy: 0.7885\n",
      "Epoch 138/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5026 - accuracy: 0.7847: 0s - los\n",
      "Epoch 139/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7833\n",
      "Epoch 140/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5016 - accuracy: 0.7863\n",
      "Epoch 141/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4956 - accuracy: 0.7916\n",
      "Epoch 142/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4928 - accuracy: 0.7915\n",
      "Epoch 143/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.5009 - accuracy: 0.7887\n",
      "Epoch 144/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4938 - accuracy: 0.7911\n",
      "Epoch 145/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4989 - accuracy: 0.7856\n",
      "Epoch 146/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4918 - accuracy: 0.7909\n",
      "Epoch 147/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4931 - accuracy: 0.7906\n",
      "Epoch 148/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4929 - accuracy: 0.7936\n",
      "Epoch 149/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4935 - accuracy: 0.7903\n",
      "Epoch 150/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4955 - accuracy: 0.7891: 0s - los\n",
      "Epoch 151/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4923 - accuracy: 0.7928\n",
      "Epoch 152/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4886 - accuracy: 0.7929\n",
      "Epoch 153/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4949 - accuracy: 0.7884\n",
      "Epoch 154/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4958 - accuracy: 0.7895\n",
      "Epoch 155/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4878 - accuracy: 0.7914\n",
      "Epoch 156/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4953 - accuracy: 0.7890\n",
      "Epoch 157/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4977 - accuracy: 0.7885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4843 - accuracy: 0.7948\n",
      "Epoch 159/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4795 - accuracy: 0.7972\n",
      "Epoch 160/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4867 - accuracy: 0.7937: 0s\n",
      "Epoch 161/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4904 - accuracy: 0.7936\n",
      "Epoch 162/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4862 - accuracy: 0.7952: 0s - loss: 0.486\n",
      "Epoch 163/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4863 - accuracy: 0.7959\n",
      "Epoch 164/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4813 - accuracy: 0.7966\n",
      "Epoch 165/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4869 - accuracy: 0.7952\n",
      "Epoch 166/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4856 - accuracy: 0.7968\n",
      "Epoch 167/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4811 - accuracy: 0.7972\n",
      "Epoch 168/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4859 - accuracy: 0.7974\n",
      "Epoch 169/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4782 - accuracy: 0.8001\n",
      "Epoch 170/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4831 - accuracy: 0.7972\n",
      "Epoch 171/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4845 - accuracy: 0.7968: 0s - l\n",
      "Epoch 172/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4841 - accuracy: 0.7972\n",
      "Epoch 173/300\n",
      "672/672 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.7982\n",
      "Epoch 174/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4967 - accuracy: 0.7932\n",
      "Epoch 175/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4887 - accuracy: 0.7932\n",
      "Epoch 176/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4764 - accuracy: 0.8002\n",
      "Epoch 177/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4758 - accuracy: 0.8021\n",
      "Epoch 178/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4804 - accuracy: 0.7991\n",
      "Epoch 179/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4779 - accuracy: 0.7996\n",
      "Epoch 180/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4751 - accuracy: 0.7981\n",
      "Epoch 181/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4801 - accuracy: 0.7964\n",
      "Epoch 182/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4806 - accuracy: 0.7965\n",
      "Epoch 183/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4724 - accuracy: 0.8003\n",
      "Epoch 184/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4769 - accuracy: 0.8002\n",
      "Epoch 185/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4790 - accuracy: 0.7965\n",
      "Epoch 186/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4685 - accuracy: 0.8024\n",
      "Epoch 187/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4712 - accuracy: 0.7998\n",
      "Epoch 188/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4706 - accuracy: 0.8007\n",
      "Epoch 189/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4860 - accuracy: 0.7952\n",
      "Epoch 190/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4811 - accuracy: 0.7972\n",
      "Epoch 191/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4834 - accuracy: 0.7981\n",
      "Epoch 192/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4722 - accuracy: 0.8016\n",
      "Epoch 193/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4747 - accuracy: 0.8023\n",
      "Epoch 194/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4751 - accuracy: 0.7993\n",
      "Epoch 195/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4719 - accuracy: 0.8019\n",
      "Epoch 196/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4690 - accuracy: 0.8018\n",
      "Epoch 197/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4727 - accuracy: 0.7992\n",
      "Epoch 198/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4763 - accuracy: 0.7991\n",
      "Epoch 199/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4852 - accuracy: 0.7905\n",
      "Epoch 200/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4670 - accuracy: 0.8038\n",
      "Epoch 201/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4669 - accuracy: 0.8040\n",
      "Epoch 202/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4673 - accuracy: 0.8025\n",
      "Epoch 203/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4699 - accuracy: 0.8013\n",
      "Epoch 204/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4733 - accuracy: 0.7996\n",
      "Epoch 205/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4912 - accuracy: 0.7890\n",
      "Epoch 206/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4808 - accuracy: 0.7972\n",
      "Epoch 207/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4755 - accuracy: 0.7982\n",
      "Epoch 208/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4602 - accuracy: 0.8077\n",
      "Epoch 209/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4644 - accuracy: 0.8055\n",
      "Epoch 210/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4686 - accuracy: 0.8015\n",
      "Epoch 211/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4657 - accuracy: 0.8034\n",
      "Epoch 212/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4684 - accuracy: 0.8052\n",
      "Epoch 213/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4676 - accuracy: 0.8026\n",
      "Epoch 214/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4617 - accuracy: 0.8025\n",
      "Epoch 215/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4614 - accuracy: 0.8075\n",
      "Epoch 216/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4631 - accuracy: 0.8031\n",
      "Epoch 217/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4564 - accuracy: 0.8083\n",
      "Epoch 218/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4666 - accuracy: 0.8043\n",
      "Epoch 219/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4641 - accuracy: 0.8055\n",
      "Epoch 220/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4604 - accuracy: 0.8048\n",
      "Epoch 221/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4837 - accuracy: 0.7965\n",
      "Epoch 222/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4700 - accuracy: 0.8030\n",
      "Epoch 223/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4617 - accuracy: 0.8046\n",
      "Epoch 224/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4573 - accuracy: 0.8087\n",
      "Epoch 225/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4549 - accuracy: 0.8089\n",
      "Epoch 226/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4551 - accuracy: 0.8086\n",
      "Epoch 227/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4627 - accuracy: 0.8056\n",
      "Epoch 228/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4692 - accuracy: 0.8020\n",
      "Epoch 229/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4597 - accuracy: 0.8064: 0s - loss: 0.4521 \n",
      "Epoch 230/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4584 - accuracy: 0.8073\n",
      "Epoch 231/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4542 - accuracy: 0.8103\n",
      "Epoch 232/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4546 - accuracy: 0.8097\n",
      "Epoch 233/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4563 - accuracy: 0.8069\n",
      "Epoch 234/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4632 - accuracy: 0.8062\n",
      "Epoch 235/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4682 - accuracy: 0.8013\n",
      "Epoch 236/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4615 - accuracy: 0.8035\n",
      "Epoch 237/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4727 - accuracy: 0.8011\n",
      "Epoch 238/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4507 - accuracy: 0.8105\n",
      "Epoch 239/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4783 - accuracy: 0.7943\n",
      "Epoch 240/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4564 - accuracy: 0.8047\n",
      "Epoch 241/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4563 - accuracy: 0.8042\n",
      "Epoch 242/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4643 - accuracy: 0.8026\n",
      "Epoch 243/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4593 - accuracy: 0.8046\n",
      "Epoch 244/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4602 - accuracy: 0.8074\n",
      "Epoch 245/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4590 - accuracy: 0.8075\n",
      "Epoch 246/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4543 - accuracy: 0.8084\n",
      "Epoch 247/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4525 - accuracy: 0.8103\n",
      "Epoch 248/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4549 - accuracy: 0.8099\n",
      "Epoch 249/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4553 - accuracy: 0.8089\n",
      "Epoch 250/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4509 - accuracy: 0.8057\n",
      "Epoch 251/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4605 - accuracy: 0.8061\n",
      "Epoch 252/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4521 - accuracy: 0.8078\n",
      "Epoch 253/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4503 - accuracy: 0.8102\n",
      "Epoch 254/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4443 - accuracy: 0.8136\n",
      "Epoch 255/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4465 - accuracy: 0.8109\n",
      "Epoch 256/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4661 - accuracy: 0.8071\n",
      "Epoch 257/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4601 - accuracy: 0.8075\n",
      "Epoch 258/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4562 - accuracy: 0.8090\n",
      "Epoch 259/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4423 - accuracy: 0.8129\n",
      "Epoch 260/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4515 - accuracy: 0.8101\n",
      "Epoch 261/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4435 - accuracy: 0.8139\n",
      "Epoch 262/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4572 - accuracy: 0.8110\n",
      "Epoch 263/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4506 - accuracy: 0.8116\n",
      "Epoch 264/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4610 - accuracy: 0.8117\n",
      "Epoch 265/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.5836 - accuracy: 0.7544\n",
      "Epoch 266/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4725 - accuracy: 0.8025: 0s - loss: 0.4810 \n",
      "Epoch 267/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4539 - accuracy: 0.8095\n",
      "Epoch 268/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4485 - accuracy: 0.8114\n",
      "Epoch 269/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4580 - accuracy: 0.8074\n",
      "Epoch 270/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4406 - accuracy: 0.8118\n",
      "Epoch 271/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4503 - accuracy: 0.8114\n",
      "Epoch 272/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4508 - accuracy: 0.8122\n",
      "Epoch 273/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4422 - accuracy: 0.8130\n",
      "Epoch 274/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4542 - accuracy: 0.8077\n",
      "Epoch 275/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4470 - accuracy: 0.8138\n",
      "Epoch 276/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4426 - accuracy: 0.8153\n",
      "Epoch 277/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4741 - accuracy: 0.7999\n",
      "Epoch 278/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4484 - accuracy: 0.8115\n",
      "Epoch 279/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4410 - accuracy: 0.8143\n",
      "Epoch 280/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4466 - accuracy: 0.8142\n",
      "Epoch 281/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4401 - accuracy: 0.8161\n",
      "Epoch 282/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4710 - accuracy: 0.8080\n",
      "Epoch 283/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.5016 - accuracy: 0.8032\n",
      "Epoch 284/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4376 - accuracy: 0.8164\n",
      "Epoch 285/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4505 - accuracy: 0.8088\n",
      "Epoch 286/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4343 - accuracy: 0.8191\n",
      "Epoch 287/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4432 - accuracy: 0.8148\n",
      "Epoch 288/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4482 - accuracy: 0.8120\n",
      "Epoch 289/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4374 - accuracy: 0.8144\n",
      "Epoch 290/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4413 - accuracy: 0.8124\n",
      "Epoch 291/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4401 - accuracy: 0.8135\n",
      "Epoch 292/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4322 - accuracy: 0.8171\n",
      "Epoch 293/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4458 - accuracy: 0.8151\n",
      "Epoch 294/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4577 - accuracy: 0.8100\n",
      "Epoch 295/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4340 - accuracy: 0.8174\n",
      "Epoch 296/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4426 - accuracy: 0.8134\n",
      "Epoch 297/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4391 - accuracy: 0.8168\n",
      "Epoch 298/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4367 - accuracy: 0.8170\n",
      "Epoch 299/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4422 - accuracy: 0.8176\n",
      "Epoch 300/300\n",
      "672/672 [==============================] - 1s 1ms/step - loss: 0.4402 - accuracy: 0.8172\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.8149 - accuracy: 0.7535\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(6,)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "\tkeras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "\tkeras.layers.Dense(3, activation=tf.nn.softmax),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(train_x_over, train_y_over, epochs=300, batch_size=71)\n",
    "\n",
    "predicted=model.predict(test_x)\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "863ece39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.6133816e-01, 8.5421499e-07, 3.8661025e-02],\n",
       "       [2.7764115e-01, 3.2805616e-01, 3.9430276e-01],\n",
       "       [8.0674446e-01, 2.4417322e-04, 1.9301137e-01],\n",
       "       ...,\n",
       "       [1.6479732e-01, 4.4941905e-01, 3.8578367e-01],\n",
       "       [9.2126632e-01, 2.6937819e-04, 7.8464277e-02],\n",
       "       [8.0794388e-01, 1.2919919e-01, 6.2856905e-02]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43669dae",
   "metadata": {},
   "source": [
    "# 예측 정확도를 계산하는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "641dfa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "predicted_plot=[]\n",
    "correct_plot=[]\n",
    "\n",
    "count_array=[0 for j in range(3)]\n",
    "\n",
    "predicted_result=[0 for j in range(len(test_y))]\n",
    "for i in range(len(test_y)):\n",
    "    maxIndex=tf.argmax(predicted[i])\n",
    "    predicted_plot.append(maxIndex-1)\n",
    "    #     print(type(maxIndex.numpy().item()))\n",
    "    index=0\n",
    "    if(y_origin[i]==2):\n",
    "        index=-1 \n",
    "    elif y_origin[i]==0:\n",
    "        index=1\n",
    "    elif y_origin[i]==1:\n",
    "        index=2\n",
    "    predicted_result[i]=index-1\n",
    "    if index==maxIndex.numpy().item():\n",
    "        count=count+1\n",
    "        count_array[index]=count_array[index]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a73aa979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.6133816e-01, 8.5421499e-07, 3.8661025e-02],\n",
       "       [2.7764115e-01, 3.2805616e-01, 3.9430276e-01],\n",
       "       [8.0674446e-01, 2.4417322e-04, 1.9301137e-01],\n",
       "       ...,\n",
       "       [1.6479732e-01, 4.4941905e-01, 3.8578367e-01],\n",
       "       [9.2126632e-01, 2.6937819e-04, 7.8464277e-02],\n",
       "       [8.0794388e-01, 1.2919919e-01, 6.2856905e-02]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82c57871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1036, 35]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1645a9e3",
   "metadata": {},
   "source": [
    "# 예측 정확도\n",
    "\n",
    "## 맞춘 개수 , 전체 개수 , 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a21b77af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071\n",
      "7728\n",
      "0.13858695652173914\n"
     ]
    }
   ],
   "source": [
    "print(count)\n",
    "print(len(test_y))\n",
    "print(count/len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3743cd09",
   "metadata": {},
   "source": [
    "# 시각화하는 부분\n",
    "## -1(감소): 100, 0(유지): 355, 1(증가):23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69bafa30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label=['Decreasing','Maintain','Increasing']\n",
    "values=[count_array[0]/8*100,count_array[1]/355*100,count_array[2]/23*100]\n",
    "\n",
    "x = np.arange(3)\n",
    "\n",
    "plt.bar(x, values)\n",
    "plt.xticks(x, label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "450d9146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ratio = [count,len(test_y)-count]\n",
    "labels = ['Correct', 'Wrong']\n",
    "\n",
    "plt.pie(ratio, labels=labels, autopct='%.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d1e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeeffcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
