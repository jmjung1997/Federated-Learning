{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2391e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense,Dropout,Activation\n",
    "from tensorflow.python.keras import metrics\n",
    "from tensorflow.python import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7c1c5",
   "metadata": {},
   "source": [
    "# 파일읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e11779",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('./modeling_data/2Weeks_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "365357e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Weight</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Step</th>\n",
       "      <th>Burn</th>\n",
       "      <th>Eat</th>\n",
       "      <th>Sleep</th>\n",
       "      <th>Height</th>\n",
       "      <th>Label</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#AAGQKY</td>\n",
       "      <td>45.0</td>\n",
       "      <td>20.544193</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>#AAGQKY</td>\n",
       "      <td>45.0</td>\n",
       "      <td>20.544193</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>#AAGQKY</td>\n",
       "      <td>45.0</td>\n",
       "      <td>20.544193</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>#AAGQKY</td>\n",
       "      <td>45.0</td>\n",
       "      <td>20.544193</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>#AAGQKY</td>\n",
       "      <td>45.0</td>\n",
       "      <td>20.544193</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>1927</td>\n",
       "      <td>#ZZLSSL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>29.048656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>1928</td>\n",
       "      <td>#ZZLSSL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>29.048656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>1929</td>\n",
       "      <td>#ZZLSSL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>29.048656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>1930</td>\n",
       "      <td>#ZZLSSL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>29.048656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>1931</td>\n",
       "      <td>#ZZLSSL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>29.048656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1932 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0       ID  Weight        BMI  Step  Burn  Eat  Sleep  Height  \\\n",
       "0              0  #AAGQKY    45.0  20.544193  72.0   0.0  0.0    0.0   148.0   \n",
       "1              1  #AAGQKY    45.0  20.544193  72.0   0.0  0.0    0.0   148.0   \n",
       "2              2  #AAGQKY    45.0  20.544193  72.0   0.0  0.0    0.0   148.0   \n",
       "3              3  #AAGQKY    45.0  20.544193  72.0   0.0  0.0    0.0   148.0   \n",
       "4              4  #AAGQKY    45.0  20.544193  72.0   0.0  0.0    0.0   148.0   \n",
       "...          ...      ...     ...        ...   ...   ...  ...    ...     ...   \n",
       "1927        1927  #ZZLSSL    68.0  29.048656   0.0   0.0  0.0    0.0   153.0   \n",
       "1928        1928  #ZZLSSL    68.0  29.048656   0.0   0.0  0.0    0.0   153.0   \n",
       "1929        1929  #ZZLSSL    68.0  29.048656   0.0   0.0  0.0    0.0   153.0   \n",
       "1930        1930  #ZZLSSL    68.0  29.048656   0.0   0.0  0.0    0.0   153.0   \n",
       "1931        1931  #ZZLSSL    68.0  29.048656   0.0   0.0  0.0    0.0   153.0   \n",
       "\n",
       "      Label  Unnamed: 10  \n",
       "0         0         73.0  \n",
       "1         0       1755.0  \n",
       "2         0        102.0  \n",
       "3         0          NaN  \n",
       "4         0          NaN  \n",
       "...     ...          ...  \n",
       "1927      0          NaN  \n",
       "1928      0          NaN  \n",
       "1929      0          NaN  \n",
       "1930      0          NaN  \n",
       "1931      0          NaN  \n",
       "\n",
       "[1932 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7427da",
   "metadata": {},
   "source": [
    "# 데이터를 필요한 부분으로 X, Y 나눠 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67abaa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,2:8]\n",
    "y_origin=df['Label']\n",
    "y=df['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4118207",
   "metadata": {},
   "source": [
    "# train, test, validation set 으로 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74280645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling\n",
    "ms=MinMaxScaler()\n",
    "X=ms.fit_transform(X)\n",
    "\n",
    "# 데이터 train, vali, test 6:2:2\n",
    "train_x=X[:1163]\n",
    "val_x=X[1163:1548]\n",
    "test_x=X[1548:]\n",
    "\n",
    "train_y=y[:1163]\n",
    "val_y=y[1163:1548]\n",
    "test_y=y[1548:]\n",
    "\n",
    "train_y=train_y.to_numpy()\n",
    "val_y=val_y.to_numpy()\n",
    "test_y=test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c238ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트:  (1163, 6) (1163,)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트:  (3153, 6) (3153,)\n",
      "SMOTE 적용 전 레이블 값 분포: \n",
      "  0    1051\n",
      " 1      63\n",
      "-1      49\n",
      "dtype: int64\n",
      "SMOTE 적용 후 레이블 값 분포: \n",
      "  0    1051\n",
      "-1    1051\n",
      " 1    1051\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "smote = SMOTE(random_state=0)\n",
    "train_x2,train_y2 = smote.fit_resample(train_x,train_y)\n",
    "\n",
    "# smote_test = SMOTE(random_state=0)\n",
    "# test_x,test_y = smote_test.fit_resample(test_x,test_y)\n",
    "print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', train_x.shape, train_y.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', train_x2.shape, train_y2.shape)\n",
    "print('SMOTE 적용 전 레이블 값 분포: \\n', pd.Series(train_y).value_counts())\n",
    "print('SMOTE 적용 후 레이블 값 분포: \\n', pd.Series(train_y2).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f404c",
   "metadata": {},
   "source": [
    "# 원핫인코딩\n",
    "\n",
    "## 예시 : 1 , 2 -> (1,0) , (0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e47ce9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y2=pd.get_dummies(train_y2)\n",
    "val_y=pd.get_dummies(val_y)\n",
    "test_y=pd.get_dummies(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e3c60db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     -1   0   1\n",
       "0     0   1   0\n",
       "1     0   1   0\n",
       "2     0   1   0\n",
       "3     0   1   0\n",
       "4     0   1   0\n",
       "..   ..  ..  ..\n",
       "379   0   1   0\n",
       "380   0   1   0\n",
       "381   0   1   0\n",
       "382   0   1   0\n",
       "383   0   1   0\n",
       "\n",
       "[384 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbff9b7",
   "metadata": {},
   "source": [
    "# 모델\n",
    "\n",
    "## Deep Neural Network\n",
    "\n",
    "## Input Feature : 6\n",
    "\n",
    "## Hidden Layer : 128 - 256 - 128\n",
    "\n",
    "## optimizer : adam, loss : categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f916abcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 1.0317 - accuracy: 0.4688 - val_loss: 1.0709 - val_accuracy: 0.4494\n",
      "Epoch 2/500\n",
      "526/526 [==============================] - 0s 859us/step - loss: 0.9419 - accuracy: 0.5496 - val_loss: 0.8494 - val_accuracy: 0.6130\n",
      "Epoch 3/500\n",
      "526/526 [==============================] - 0s 874us/step - loss: 0.8829 - accuracy: 0.5905 - val_loss: 0.7674 - val_accuracy: 0.6182\n",
      "Epoch 4/500\n",
      "526/526 [==============================] - 0s 850us/step - loss: 0.8472 - accuracy: 0.6181 - val_loss: 0.7792 - val_accuracy: 0.5922\n",
      "Epoch 5/500\n",
      "526/526 [==============================] - 0s 850us/step - loss: 0.7922 - accuracy: 0.6384 - val_loss: 0.9722 - val_accuracy: 0.4987\n",
      "Epoch 6/500\n",
      "526/526 [==============================] - 0s 897us/step - loss: 0.7374 - accuracy: 0.6749 - val_loss: 0.8562 - val_accuracy: 0.5429\n",
      "Epoch 7/500\n",
      "526/526 [==============================] - 0s 873us/step - loss: 0.6857 - accuracy: 0.7114 - val_loss: 0.8830 - val_accuracy: 0.5766\n",
      "Epoch 8/500\n",
      "526/526 [==============================] - 0s 882us/step - loss: 0.6391 - accuracy: 0.7301 - val_loss: 1.1021 - val_accuracy: 0.4805\n",
      "Epoch 9/500\n",
      "526/526 [==============================] - 0s 857us/step - loss: 0.5935 - accuracy: 0.7504 - val_loss: 0.9926 - val_accuracy: 0.5221\n",
      "Epoch 10/500\n",
      "526/526 [==============================] - 0s 865us/step - loss: 0.5578 - accuracy: 0.7647 - val_loss: 1.1006 - val_accuracy: 0.5429\n",
      "Epoch 11/500\n",
      "526/526 [==============================] - 0s 878us/step - loss: 0.5324 - accuracy: 0.7751 - val_loss: 1.0167 - val_accuracy: 0.6675\n",
      "Epoch 12/500\n",
      "526/526 [==============================] - 0s 878us/step - loss: 0.5022 - accuracy: 0.7967 - val_loss: 1.0876 - val_accuracy: 0.5948\n",
      "Epoch 13/500\n",
      "526/526 [==============================] - 0s 880us/step - loss: 0.4739 - accuracy: 0.8065 - val_loss: 1.1660 - val_accuracy: 0.5662\n",
      "Epoch 14/500\n",
      "526/526 [==============================] - 0s 876us/step - loss: 0.4507 - accuracy: 0.8173 - val_loss: 1.1375 - val_accuracy: 0.6052\n",
      "Epoch 15/500\n",
      "526/526 [==============================] - 0s 865us/step - loss: 0.4434 - accuracy: 0.8214 - val_loss: 1.0825 - val_accuracy: 0.6571\n",
      "Epoch 16/500\n",
      "526/526 [==============================] - 0s 871us/step - loss: 0.4183 - accuracy: 0.8348 - val_loss: 1.1163 - val_accuracy: 0.6442\n",
      "Epoch 17/500\n",
      "526/526 [==============================] - 0s 859us/step - loss: 0.4152 - accuracy: 0.8351 - val_loss: 1.0955 - val_accuracy: 0.6649\n",
      "Epoch 18/500\n",
      "526/526 [==============================] - 0s 880us/step - loss: 0.3873 - accuracy: 0.8414 - val_loss: 1.2677 - val_accuracy: 0.6545\n",
      "Epoch 19/500\n",
      "526/526 [==============================] - 0s 859us/step - loss: 0.3782 - accuracy: 0.8519 - val_loss: 1.1260 - val_accuracy: 0.7091\n",
      "Epoch 20/500\n",
      "526/526 [==============================] - 0s 848us/step - loss: 0.3707 - accuracy: 0.8522 - val_loss: 1.4467 - val_accuracy: 0.6156\n",
      "Epoch 21/500\n",
      "526/526 [==============================] - 0s 890us/step - loss: 0.3520 - accuracy: 0.8598 - val_loss: 1.1978 - val_accuracy: 0.6961\n",
      "Epoch 22/500\n",
      "526/526 [==============================] - 0s 882us/step - loss: 0.3543 - accuracy: 0.8506 - val_loss: 1.3420 - val_accuracy: 0.6390\n",
      "Epoch 23/500\n",
      "526/526 [==============================] - 0s 859us/step - loss: 0.3559 - accuracy: 0.8519 - val_loss: 1.3342 - val_accuracy: 0.6727\n",
      "Epoch 24/500\n",
      "526/526 [==============================] - 0s 869us/step - loss: 0.3436 - accuracy: 0.8652 - val_loss: 1.4639 - val_accuracy: 0.6286\n",
      "Epoch 25/500\n",
      "526/526 [==============================] - 0s 886us/step - loss: 0.3438 - accuracy: 0.8611 - val_loss: 1.3810 - val_accuracy: 0.6390\n",
      "Epoch 26/500\n",
      "526/526 [==============================] - 0s 873us/step - loss: 0.3288 - accuracy: 0.8636 - val_loss: 1.3692 - val_accuracy: 0.6831\n",
      "Epoch 27/500\n",
      "526/526 [==============================] - 0s 834us/step - loss: 0.3353 - accuracy: 0.8639 - val_loss: 1.2479 - val_accuracy: 0.7091\n",
      "Epoch 28/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.3163 - accuracy: 0.8754 - val_loss: 1.3786 - val_accuracy: 0.6987\n",
      "Epoch 29/500\n",
      "526/526 [==============================] - 0s 829us/step - loss: 0.3058 - accuracy: 0.8842 - val_loss: 1.4821 - val_accuracy: 0.6571\n",
      "Epoch 30/500\n",
      "526/526 [==============================] - 0s 828us/step - loss: 0.3139 - accuracy: 0.8741 - val_loss: 1.2441 - val_accuracy: 0.7143\n",
      "Epoch 31/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.2983 - accuracy: 0.8750 - val_loss: 1.5183 - val_accuracy: 0.6597\n",
      "Epoch 32/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.2956 - accuracy: 0.8798 - val_loss: 1.3820 - val_accuracy: 0.6857\n",
      "Epoch 33/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.2939 - accuracy: 0.8814 - val_loss: 1.6364 - val_accuracy: 0.6130\n",
      "Epoch 34/500\n",
      "526/526 [==============================] - 0s 833us/step - loss: 0.2896 - accuracy: 0.8830 - val_loss: 1.6342 - val_accuracy: 0.6442\n",
      "Epoch 35/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.2898 - accuracy: 0.8807 - val_loss: 1.6042 - val_accuracy: 0.6857\n",
      "Epoch 36/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.2917 - accuracy: 0.8855 - val_loss: 1.6435 - val_accuracy: 0.6649\n",
      "Epoch 37/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.2915 - accuracy: 0.8833 - val_loss: 1.6080 - val_accuracy: 0.6857\n",
      "Epoch 38/500\n",
      "526/526 [==============================] - 0s 809us/step - loss: 0.2679 - accuracy: 0.8918 - val_loss: 1.5685 - val_accuracy: 0.6857\n",
      "Epoch 39/500\n",
      "526/526 [==============================] - 0s 838us/step - loss: 0.2765 - accuracy: 0.8865 - val_loss: 1.5611 - val_accuracy: 0.6571\n",
      "Epoch 40/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.2772 - accuracy: 0.8827 - val_loss: 1.7384 - val_accuracy: 0.6727\n",
      "Epoch 41/500\n",
      "526/526 [==============================] - 0s 843us/step - loss: 0.2751 - accuracy: 0.8915 - val_loss: 1.6206 - val_accuracy: 0.6727\n",
      "Epoch 42/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.2485 - accuracy: 0.9010 - val_loss: 1.6134 - val_accuracy: 0.6883\n",
      "Epoch 43/500\n",
      "526/526 [==============================] - 0s 844us/step - loss: 0.2589 - accuracy: 0.8963 - val_loss: 1.7477 - val_accuracy: 0.6623\n",
      "Epoch 44/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.2586 - accuracy: 0.8957 - val_loss: 1.6709 - val_accuracy: 0.6545\n",
      "Epoch 45/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.2564 - accuracy: 0.8941 - val_loss: 1.7353 - val_accuracy: 0.6831\n",
      "Epoch 46/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.2417 - accuracy: 0.9049 - val_loss: 1.6882 - val_accuracy: 0.6779\n",
      "Epoch 47/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.2705 - accuracy: 0.8915 - val_loss: 1.7311 - val_accuracy: 0.6545\n",
      "Epoch 48/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.2454 - accuracy: 0.9001 - val_loss: 1.7355 - val_accuracy: 0.6545\n",
      "Epoch 49/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.2545 - accuracy: 0.8947 - val_loss: 1.7798 - val_accuracy: 0.6831\n",
      "Epoch 50/500\n",
      "526/526 [==============================] - 0s 798us/step - loss: 0.2375 - accuracy: 0.9090 - val_loss: 1.8375 - val_accuracy: 0.6571\n",
      "Epoch 51/500\n",
      "526/526 [==============================] - 0s 816us/step - loss: 0.2404 - accuracy: 0.8995 - val_loss: 1.7645 - val_accuracy: 0.6883\n",
      "Epoch 52/500\n",
      "526/526 [==============================] - 0s 798us/step - loss: 0.2387 - accuracy: 0.9099 - val_loss: 1.6855 - val_accuracy: 0.7065\n",
      "Epoch 53/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.2327 - accuracy: 0.9026 - val_loss: 1.7182 - val_accuracy: 0.7325\n",
      "Epoch 54/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.2381 - accuracy: 0.9007 - val_loss: 1.8408 - val_accuracy: 0.6597\n",
      "Epoch 55/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.2355 - accuracy: 0.8982 - val_loss: 1.8058 - val_accuracy: 0.6779\n",
      "Epoch 56/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.2322 - accuracy: 0.9068 - val_loss: 1.9746 - val_accuracy: 0.6545\n",
      "Epoch 57/500\n",
      "526/526 [==============================] - 0s 802us/step - loss: 0.2139 - accuracy: 0.9141 - val_loss: 1.8990 - val_accuracy: 0.6545\n",
      "Epoch 58/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.2295 - accuracy: 0.9052 - val_loss: 1.7712 - val_accuracy: 0.6987\n",
      "Epoch 59/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.2306 - accuracy: 0.9074 - val_loss: 1.9118 - val_accuracy: 0.6675\n",
      "Epoch 60/500\n",
      "526/526 [==============================] - 0s 833us/step - loss: 0.2178 - accuracy: 0.9144 - val_loss: 1.9244 - val_accuracy: 0.6701\n",
      "Epoch 61/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.2096 - accuracy: 0.9150 - val_loss: 1.9718 - val_accuracy: 0.7169\n",
      "Epoch 62/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.2416 - accuracy: 0.9029 - val_loss: 1.7834 - val_accuracy: 0.6883\n",
      "Epoch 63/500\n",
      "526/526 [==============================] - 0s 829us/step - loss: 0.2033 - accuracy: 0.9172 - val_loss: 1.9098 - val_accuracy: 0.6805\n",
      "Epoch 64/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.2023 - accuracy: 0.9198 - val_loss: 2.0077 - val_accuracy: 0.6519\n",
      "Epoch 65/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.2174 - accuracy: 0.9080 - val_loss: 1.9553 - val_accuracy: 0.6623\n",
      "Epoch 66/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1967 - accuracy: 0.9194 - val_loss: 2.0306 - val_accuracy: 0.6779\n",
      "Epoch 67/500\n",
      "526/526 [==============================] - 0s 827us/step - loss: 0.2076 - accuracy: 0.9112 - val_loss: 1.9313 - val_accuracy: 0.6909\n",
      "Epoch 68/500\n",
      "526/526 [==============================] - 0s 834us/step - loss: 0.2023 - accuracy: 0.9169 - val_loss: 1.9127 - val_accuracy: 0.6987\n",
      "Epoch 69/500\n",
      "526/526 [==============================] - 0s 829us/step - loss: 0.2040 - accuracy: 0.9137 - val_loss: 2.0850 - val_accuracy: 0.6831\n",
      "Epoch 70/500\n",
      "526/526 [==============================] - 0s 833us/step - loss: 0.2126 - accuracy: 0.9115 - val_loss: 1.9650 - val_accuracy: 0.6623\n",
      "Epoch 71/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1967 - accuracy: 0.9217 - val_loss: 2.0345 - val_accuracy: 0.6727\n",
      "Epoch 72/500\n",
      "526/526 [==============================] - 0s 820us/step - loss: 0.1928 - accuracy: 0.9239 - val_loss: 2.0695 - val_accuracy: 0.6779\n",
      "Epoch 73/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1961 - accuracy: 0.9194 - val_loss: 2.0506 - val_accuracy: 0.6727\n",
      "Epoch 74/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.2074 - accuracy: 0.9179 - val_loss: 1.9495 - val_accuracy: 0.6805\n",
      "Epoch 75/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.2034 - accuracy: 0.9144 - val_loss: 1.9519 - val_accuracy: 0.7221\n",
      "Epoch 76/500\n",
      "526/526 [==============================] - 0s 822us/step - loss: 0.1994 - accuracy: 0.9179 - val_loss: 1.9355 - val_accuracy: 0.7247\n",
      "Epoch 77/500\n",
      "526/526 [==============================] - 0s 829us/step - loss: 0.2122 - accuracy: 0.9163 - val_loss: 2.1042 - val_accuracy: 0.6753\n",
      "Epoch 78/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1794 - accuracy: 0.9229 - val_loss: 2.0357 - val_accuracy: 0.7117\n",
      "Epoch 79/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.2109 - accuracy: 0.9096 - val_loss: 2.0029 - val_accuracy: 0.6675\n",
      "Epoch 80/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.1758 - accuracy: 0.9293 - val_loss: 2.1643 - val_accuracy: 0.6701\n",
      "Epoch 81/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.1845 - accuracy: 0.9239 - val_loss: 2.0184 - val_accuracy: 0.7325\n",
      "Epoch 82/500\n",
      "526/526 [==============================] - 0s 830us/step - loss: 0.1950 - accuracy: 0.9175 - val_loss: 2.2417 - val_accuracy: 0.6727\n",
      "Epoch 83/500\n",
      "526/526 [==============================] - 0s 829us/step - loss: 0.2021 - accuracy: 0.9194 - val_loss: 2.2116 - val_accuracy: 0.6623\n",
      "Epoch 84/500\n",
      "526/526 [==============================] - 0s 827us/step - loss: 0.1865 - accuracy: 0.9223 - val_loss: 2.3927 - val_accuracy: 0.6104\n",
      "Epoch 85/500\n",
      "526/526 [==============================] - 0s 831us/step - loss: 0.2058 - accuracy: 0.9191 - val_loss: 2.0916 - val_accuracy: 0.6935\n",
      "Epoch 86/500\n",
      "526/526 [==============================] - 0s 918us/step - loss: 0.1764 - accuracy: 0.9280 - val_loss: 2.2180 - val_accuracy: 0.7065\n",
      "Epoch 87/500\n",
      "526/526 [==============================] - 0s 861us/step - loss: 0.1841 - accuracy: 0.9232 - val_loss: 2.3212 - val_accuracy: 0.6701\n",
      "Epoch 88/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1679 - accuracy: 0.9312 - val_loss: 2.0481 - val_accuracy: 0.6987\n",
      "Epoch 89/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.1806 - accuracy: 0.9280 - val_loss: 2.1425 - val_accuracy: 0.7169\n",
      "Epoch 90/500\n",
      "526/526 [==============================] - 0s 894us/step - loss: 0.1866 - accuracy: 0.9271 - val_loss: 2.1219 - val_accuracy: 0.6883\n",
      "Epoch 91/500\n",
      "526/526 [==============================] - 0s 844us/step - loss: 0.1717 - accuracy: 0.9242 - val_loss: 2.1650 - val_accuracy: 0.6649\n",
      "Epoch 92/500\n",
      "526/526 [==============================] - 0s 832us/step - loss: 0.1820 - accuracy: 0.9223 - val_loss: 2.2917 - val_accuracy: 0.6831\n",
      "Epoch 93/500\n",
      "526/526 [==============================] - 0s 863us/step - loss: 0.1854 - accuracy: 0.9213 - val_loss: 2.3068 - val_accuracy: 0.7117\n",
      "Epoch 94/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.1627 - accuracy: 0.9366 - val_loss: 2.1369 - val_accuracy: 0.6961\n",
      "Epoch 95/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.1729 - accuracy: 0.9302 - val_loss: 2.0006 - val_accuracy: 0.7065\n",
      "Epoch 96/500\n",
      "526/526 [==============================] - 0s 831us/step - loss: 0.1694 - accuracy: 0.9236 - val_loss: 2.3974 - val_accuracy: 0.6519\n",
      "Epoch 97/500\n",
      "526/526 [==============================] - 0s 942us/step - loss: 0.1725 - accuracy: 0.9296 - val_loss: 2.1957 - val_accuracy: 0.6701\n",
      "Epoch 98/500\n",
      "526/526 [==============================] - 0s 882us/step - loss: 0.1773 - accuracy: 0.9290 - val_loss: 2.4538 - val_accuracy: 0.6260\n",
      "Epoch 99/500\n",
      "526/526 [==============================] - 0s 871us/step - loss: 0.1867 - accuracy: 0.9166 - val_loss: 2.2316 - val_accuracy: 0.6961\n",
      "Epoch 100/500\n",
      "526/526 [==============================] - 0s 865us/step - loss: 0.1641 - accuracy: 0.9321 - val_loss: 2.3850 - val_accuracy: 0.6831\n",
      "Epoch 101/500\n",
      "526/526 [==============================] - 0s 859us/step - loss: 0.1879 - accuracy: 0.9245 - val_loss: 2.1559 - val_accuracy: 0.7091\n",
      "Epoch 102/500\n",
      "526/526 [==============================] - 1s 957us/step - loss: 0.1697 - accuracy: 0.9267 - val_loss: 2.3409 - val_accuracy: 0.7013\n",
      "Epoch 103/500\n",
      "526/526 [==============================] - 0s 853us/step - loss: 0.1806 - accuracy: 0.9267 - val_loss: 2.3695 - val_accuracy: 0.6831\n",
      "Epoch 104/500\n",
      "526/526 [==============================] - 0s 948us/step - loss: 0.1618 - accuracy: 0.9337 - val_loss: 2.3292 - val_accuracy: 0.7169\n",
      "Epoch 105/500\n",
      "526/526 [==============================] - 0s 868us/step - loss: 0.1626 - accuracy: 0.9312 - val_loss: 2.5447 - val_accuracy: 0.6519\n",
      "Epoch 106/500\n",
      "526/526 [==============================] - 0s 934us/step - loss: 0.1564 - accuracy: 0.9366 - val_loss: 2.3465 - val_accuracy: 0.7403\n",
      "Epoch 107/500\n",
      "526/526 [==============================] - 1s 956us/step - loss: 0.1673 - accuracy: 0.9302 - val_loss: 2.4446 - val_accuracy: 0.6935\n",
      "Epoch 108/500\n",
      "526/526 [==============================] - 1s 1ms/step - loss: 0.1731 - accuracy: 0.9274 - val_loss: 2.3419 - val_accuracy: 0.6961\n",
      "Epoch 109/500\n",
      "526/526 [==============================] - 0s 892us/step - loss: 0.1544 - accuracy: 0.9385 - val_loss: 2.6772 - val_accuracy: 0.6390\n",
      "Epoch 110/500\n",
      "526/526 [==============================] - 0s 861us/step - loss: 0.1663 - accuracy: 0.9343 - val_loss: 2.3848 - val_accuracy: 0.7143\n",
      "Epoch 111/500\n",
      "526/526 [==============================] - 0s 834us/step - loss: 0.1539 - accuracy: 0.9350 - val_loss: 2.3322 - val_accuracy: 0.7532\n",
      "Epoch 112/500\n",
      "526/526 [==============================] - 0s 867us/step - loss: 0.1685 - accuracy: 0.9264 - val_loss: 2.2937 - val_accuracy: 0.6987\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526/526 [==============================] - 0s 838us/step - loss: 0.1598 - accuracy: 0.9318 - val_loss: 2.3711 - val_accuracy: 0.7039\n",
      "Epoch 114/500\n",
      "526/526 [==============================] - 0s 880us/step - loss: 0.1614 - accuracy: 0.9337 - val_loss: 2.3503 - val_accuracy: 0.7143\n",
      "Epoch 115/500\n",
      "526/526 [==============================] - 0s 826us/step - loss: 0.1640 - accuracy: 0.9347 - val_loss: 2.5255 - val_accuracy: 0.7013\n",
      "Epoch 116/500\n",
      "526/526 [==============================] - 0s 836us/step - loss: 0.1585 - accuracy: 0.9305 - val_loss: 2.4087 - val_accuracy: 0.7013\n",
      "Epoch 117/500\n",
      "526/526 [==============================] - 0s 865us/step - loss: 0.1632 - accuracy: 0.9315 - val_loss: 2.3816 - val_accuracy: 0.6857\n",
      "Epoch 118/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.1519 - accuracy: 0.9353 - val_loss: 2.5692 - val_accuracy: 0.6909\n",
      "Epoch 119/500\n",
      "526/526 [==============================] - 0s 905us/step - loss: 0.1499 - accuracy: 0.9359 - val_loss: 2.5329 - val_accuracy: 0.6779\n",
      "Epoch 120/500\n",
      "526/526 [==============================] - 0s 837us/step - loss: 0.1625 - accuracy: 0.9363 - val_loss: 2.5613 - val_accuracy: 0.6779\n",
      "Epoch 121/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.1654 - accuracy: 0.9331 - val_loss: 2.4720 - val_accuracy: 0.6909\n",
      "Epoch 122/500\n",
      "526/526 [==============================] - 0s 829us/step - loss: 0.1451 - accuracy: 0.9385 - val_loss: 2.3686 - val_accuracy: 0.7091\n",
      "Epoch 123/500\n",
      "526/526 [==============================] - 0s 836us/step - loss: 0.1745 - accuracy: 0.9290 - val_loss: 2.4811 - val_accuracy: 0.6883\n",
      "Epoch 124/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.1478 - accuracy: 0.9356 - val_loss: 2.4685 - val_accuracy: 0.7065\n",
      "Epoch 125/500\n",
      "526/526 [==============================] - 0s 829us/step - loss: 0.1515 - accuracy: 0.9407 - val_loss: 2.3243 - val_accuracy: 0.7506\n",
      "Epoch 126/500\n",
      "526/526 [==============================] - 0s 836us/step - loss: 0.1517 - accuracy: 0.9328 - val_loss: 2.6754 - val_accuracy: 0.6727\n",
      "Epoch 127/500\n",
      "526/526 [==============================] - 0s 838us/step - loss: 0.1530 - accuracy: 0.9378 - val_loss: 2.6452 - val_accuracy: 0.6753\n",
      "Epoch 128/500\n",
      "526/526 [==============================] - 0s 833us/step - loss: 0.1587 - accuracy: 0.9283 - val_loss: 2.5809 - val_accuracy: 0.6519\n",
      "Epoch 129/500\n",
      "526/526 [==============================] - 0s 828us/step - loss: 0.1519 - accuracy: 0.9372 - val_loss: 2.5927 - val_accuracy: 0.6649\n",
      "Epoch 130/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.1563 - accuracy: 0.9321 - val_loss: 2.5876 - val_accuracy: 0.7039\n",
      "Epoch 131/500\n",
      "526/526 [==============================] - 0s 831us/step - loss: 0.1499 - accuracy: 0.9353 - val_loss: 2.7673 - val_accuracy: 0.7091\n",
      "Epoch 132/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1334 - accuracy: 0.9435 - val_loss: 2.6898 - val_accuracy: 0.6935\n",
      "Epoch 133/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.1443 - accuracy: 0.9420 - val_loss: 2.7811 - val_accuracy: 0.6701\n",
      "Epoch 134/500\n",
      "526/526 [==============================] - 0s 816us/step - loss: 0.1690 - accuracy: 0.9305 - val_loss: 2.5384 - val_accuracy: 0.6597\n",
      "Epoch 135/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.1477 - accuracy: 0.9385 - val_loss: 2.4074 - val_accuracy: 0.7195\n",
      "Epoch 136/500\n",
      "526/526 [==============================] - 0s 827us/step - loss: 0.1417 - accuracy: 0.9343 - val_loss: 2.8662 - val_accuracy: 0.6779\n",
      "Epoch 137/500\n",
      "526/526 [==============================] - 0s 824us/step - loss: 0.1468 - accuracy: 0.9356 - val_loss: 2.7262 - val_accuracy: 0.6675\n",
      "Epoch 138/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.1558 - accuracy: 0.9356 - val_loss: 2.6150 - val_accuracy: 0.7143\n",
      "Epoch 139/500\n",
      "526/526 [==============================] - 0s 827us/step - loss: 0.1376 - accuracy: 0.9432 - val_loss: 2.7588 - val_accuracy: 0.6961\n",
      "Epoch 140/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1389 - accuracy: 0.9404 - val_loss: 2.7552 - val_accuracy: 0.6805\n",
      "Epoch 141/500\n",
      "526/526 [==============================] - 0s 829us/step - loss: 0.1449 - accuracy: 0.9378 - val_loss: 2.7355 - val_accuracy: 0.7039\n",
      "Epoch 142/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.1516 - accuracy: 0.9350 - val_loss: 2.6587 - val_accuracy: 0.7273\n",
      "Epoch 143/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1462 - accuracy: 0.9369 - val_loss: 2.7128 - val_accuracy: 0.6987\n",
      "Epoch 144/500\n",
      "526/526 [==============================] - 0s 831us/step - loss: 0.1457 - accuracy: 0.9359 - val_loss: 2.7562 - val_accuracy: 0.6935\n",
      "Epoch 145/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1504 - accuracy: 0.9347 - val_loss: 2.8217 - val_accuracy: 0.6857\n",
      "Epoch 146/500\n",
      "526/526 [==============================] - 0s 820us/step - loss: 0.1428 - accuracy: 0.9397 - val_loss: 2.6555 - val_accuracy: 0.7247\n",
      "Epoch 147/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.1377 - accuracy: 0.9397 - val_loss: 2.7877 - val_accuracy: 0.7117\n",
      "Epoch 148/500\n",
      "526/526 [==============================] - 0s 827us/step - loss: 0.1427 - accuracy: 0.9366 - val_loss: 2.7605 - val_accuracy: 0.6831\n",
      "Epoch 149/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1363 - accuracy: 0.9394 - val_loss: 2.8109 - val_accuracy: 0.6935\n",
      "Epoch 150/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1317 - accuracy: 0.9470 - val_loss: 2.7731 - val_accuracy: 0.6987\n",
      "Epoch 151/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.1487 - accuracy: 0.9420 - val_loss: 2.7759 - val_accuracy: 0.7013\n",
      "Epoch 152/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1608 - accuracy: 0.9350 - val_loss: 2.8734 - val_accuracy: 0.6935\n",
      "Epoch 153/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.1377 - accuracy: 0.9413 - val_loss: 2.9509 - val_accuracy: 0.6727\n",
      "Epoch 154/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.1316 - accuracy: 0.9410 - val_loss: 2.8026 - val_accuracy: 0.7117\n",
      "Epoch 155/500\n",
      "526/526 [==============================] - 0s 804us/step - loss: 0.1387 - accuracy: 0.9429 - val_loss: 2.5632 - val_accuracy: 0.7247\n",
      "Epoch 156/500\n",
      "526/526 [==============================] - 0s 804us/step - loss: 0.1476 - accuracy: 0.9413 - val_loss: 2.7076 - val_accuracy: 0.6857\n",
      "Epoch 157/500\n",
      "526/526 [==============================] - 0s 800us/step - loss: 0.1543 - accuracy: 0.9391 - val_loss: 2.5447 - val_accuracy: 0.6857\n",
      "Epoch 158/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1339 - accuracy: 0.9401 - val_loss: 2.7500 - val_accuracy: 0.7117\n",
      "Epoch 159/500\n",
      "526/526 [==============================] - 0s 798us/step - loss: 0.1320 - accuracy: 0.9461 - val_loss: 2.6834 - val_accuracy: 0.7403\n",
      "Epoch 160/500\n",
      "526/526 [==============================] - 0s 800us/step - loss: 0.1297 - accuracy: 0.9442 - val_loss: 2.8502 - val_accuracy: 0.6571\n",
      "Epoch 161/500\n",
      "526/526 [==============================] - 0s 796us/step - loss: 0.1372 - accuracy: 0.9467 - val_loss: 2.7591 - val_accuracy: 0.7013\n",
      "Epoch 162/500\n",
      "526/526 [==============================] - 0s 798us/step - loss: 0.1387 - accuracy: 0.9410 - val_loss: 2.7375 - val_accuracy: 0.7039\n",
      "Epoch 163/500\n",
      "526/526 [==============================] - 0s 800us/step - loss: 0.1365 - accuracy: 0.9410 - val_loss: 2.7683 - val_accuracy: 0.7013\n",
      "Epoch 164/500\n",
      "526/526 [==============================] - 0s 803us/step - loss: 0.1303 - accuracy: 0.9483 - val_loss: 2.5739 - val_accuracy: 0.7481\n",
      "Epoch 165/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.1383 - accuracy: 0.9416 - val_loss: 2.8978 - val_accuracy: 0.6831\n",
      "Epoch 166/500\n",
      "526/526 [==============================] - 0s 798us/step - loss: 0.1347 - accuracy: 0.9401 - val_loss: 2.8684 - val_accuracy: 0.6883\n",
      "Epoch 167/500\n",
      "526/526 [==============================] - 0s 796us/step - loss: 0.1219 - accuracy: 0.9531 - val_loss: 2.7586 - val_accuracy: 0.7039\n",
      "Epoch 168/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.1329 - accuracy: 0.9423 - val_loss: 2.7135 - val_accuracy: 0.6935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.1505 - accuracy: 0.9391 - val_loss: 2.6909 - val_accuracy: 0.7325\n",
      "Epoch 170/500\n",
      "526/526 [==============================] - 0s 798us/step - loss: 0.1245 - accuracy: 0.9464 - val_loss: 2.9104 - val_accuracy: 0.6623\n",
      "Epoch 171/500\n",
      "526/526 [==============================] - 0s 802us/step - loss: 0.1474 - accuracy: 0.9366 - val_loss: 2.6927 - val_accuracy: 0.7169\n",
      "Epoch 172/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.1358 - accuracy: 0.9423 - val_loss: 2.8295 - val_accuracy: 0.6727\n",
      "Epoch 173/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.1270 - accuracy: 0.9461 - val_loss: 2.7639 - val_accuracy: 0.6883\n",
      "Epoch 174/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1351 - accuracy: 0.9401 - val_loss: 2.8387 - val_accuracy: 0.6623\n",
      "Epoch 175/500\n",
      "526/526 [==============================] - 0s 805us/step - loss: 0.1387 - accuracy: 0.9404 - val_loss: 2.7572 - val_accuracy: 0.6909\n",
      "Epoch 176/500\n",
      "526/526 [==============================] - 0s 804us/step - loss: 0.1230 - accuracy: 0.9458 - val_loss: 2.7013 - val_accuracy: 0.7247\n",
      "Epoch 177/500\n",
      "526/526 [==============================] - 0s 802us/step - loss: 0.1342 - accuracy: 0.9429 - val_loss: 2.9699 - val_accuracy: 0.6987\n",
      "Epoch 178/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.1257 - accuracy: 0.9458 - val_loss: 3.0149 - val_accuracy: 0.6935\n",
      "Epoch 179/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1396 - accuracy: 0.9423 - val_loss: 2.9072 - val_accuracy: 0.6727\n",
      "Epoch 180/500\n",
      "526/526 [==============================] - 0s 802us/step - loss: 0.1216 - accuracy: 0.9483 - val_loss: 2.9505 - val_accuracy: 0.6727\n",
      "Epoch 181/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.1282 - accuracy: 0.9432 - val_loss: 2.8641 - val_accuracy: 0.7351\n",
      "Epoch 182/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.1246 - accuracy: 0.9489 - val_loss: 2.8602 - val_accuracy: 0.7325\n",
      "Epoch 183/500\n",
      "526/526 [==============================] - 0s 794us/step - loss: 0.1418 - accuracy: 0.9369 - val_loss: 3.0453 - val_accuracy: 0.6597\n",
      "Epoch 184/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.1359 - accuracy: 0.9426 - val_loss: 2.5672 - val_accuracy: 0.7662\n",
      "Epoch 185/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.1162 - accuracy: 0.9489 - val_loss: 2.8154 - val_accuracy: 0.7065\n",
      "Epoch 186/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1327 - accuracy: 0.9432 - val_loss: 2.8432 - val_accuracy: 0.7013\n",
      "Epoch 187/500\n",
      "526/526 [==============================] - 0s 800us/step - loss: 0.1238 - accuracy: 0.9458 - val_loss: 2.8619 - val_accuracy: 0.7013\n",
      "Epoch 188/500\n",
      "526/526 [==============================] - 0s 802us/step - loss: 0.1193 - accuracy: 0.9477 - val_loss: 2.9336 - val_accuracy: 0.7039\n",
      "Epoch 189/500\n",
      "526/526 [==============================] - 0s 798us/step - loss: 0.1477 - accuracy: 0.9385 - val_loss: 2.9657 - val_accuracy: 0.6779\n",
      "Epoch 190/500\n",
      "526/526 [==============================] - 0s 800us/step - loss: 0.1253 - accuracy: 0.9454 - val_loss: 2.9766 - val_accuracy: 0.6779\n",
      "Epoch 191/500\n",
      "526/526 [==============================] - 0s 822us/step - loss: 0.1230 - accuracy: 0.9508 - val_loss: 2.8712 - val_accuracy: 0.6987\n",
      "Epoch 192/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1329 - accuracy: 0.9445 - val_loss: 2.9130 - val_accuracy: 0.6753\n",
      "Epoch 193/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1297 - accuracy: 0.9432 - val_loss: 2.7546 - val_accuracy: 0.7143\n",
      "Epoch 194/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1178 - accuracy: 0.9493 - val_loss: 2.9684 - val_accuracy: 0.6883\n",
      "Epoch 195/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.1165 - accuracy: 0.9537 - val_loss: 2.9760 - val_accuracy: 0.6961\n",
      "Epoch 196/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.1233 - accuracy: 0.9464 - val_loss: 3.0005 - val_accuracy: 0.6831\n",
      "Epoch 197/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.1244 - accuracy: 0.9445 - val_loss: 2.8926 - val_accuracy: 0.7247\n",
      "Epoch 198/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1286 - accuracy: 0.9439 - val_loss: 2.9305 - val_accuracy: 0.6805\n",
      "Epoch 199/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.1247 - accuracy: 0.9470 - val_loss: 3.0109 - val_accuracy: 0.7403\n",
      "Epoch 200/500\n",
      "526/526 [==============================] - 0s 829us/step - loss: 0.1285 - accuracy: 0.9445 - val_loss: 2.9004 - val_accuracy: 0.7195\n",
      "Epoch 201/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.1114 - accuracy: 0.9515 - val_loss: 3.0443 - val_accuracy: 0.6909\n",
      "Epoch 202/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.1273 - accuracy: 0.9483 - val_loss: 2.8106 - val_accuracy: 0.7221\n",
      "Epoch 203/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.1334 - accuracy: 0.9413 - val_loss: 3.0482 - val_accuracy: 0.7351\n",
      "Epoch 204/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1089 - accuracy: 0.9531 - val_loss: 2.9594 - val_accuracy: 0.6961\n",
      "Epoch 205/500\n",
      "526/526 [==============================] - 0s 827us/step - loss: 0.1271 - accuracy: 0.9454 - val_loss: 3.1560 - val_accuracy: 0.6519\n",
      "Epoch 206/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.1258 - accuracy: 0.9470 - val_loss: 2.7113 - val_accuracy: 0.7429\n",
      "Epoch 207/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.1130 - accuracy: 0.9508 - val_loss: 2.8779 - val_accuracy: 0.7247\n",
      "Epoch 208/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.1204 - accuracy: 0.9486 - val_loss: 2.9918 - val_accuracy: 0.6883\n",
      "Epoch 209/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.1187 - accuracy: 0.9451 - val_loss: 2.8388 - val_accuracy: 0.7377\n",
      "Epoch 210/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.1169 - accuracy: 0.9505 - val_loss: 2.9815 - val_accuracy: 0.6961\n",
      "Epoch 211/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1257 - accuracy: 0.9480 - val_loss: 2.8893 - val_accuracy: 0.7169\n",
      "Epoch 212/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1350 - accuracy: 0.9397 - val_loss: 2.8833 - val_accuracy: 0.7221\n",
      "Epoch 213/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.1123 - accuracy: 0.9496 - val_loss: 3.1520 - val_accuracy: 0.7013\n",
      "Epoch 214/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1254 - accuracy: 0.9477 - val_loss: 2.9448 - val_accuracy: 0.7377\n",
      "Epoch 215/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.1151 - accuracy: 0.9505 - val_loss: 3.0069 - val_accuracy: 0.6987\n",
      "Epoch 216/500\n",
      "526/526 [==============================] - 0s 834us/step - loss: 0.1289 - accuracy: 0.9461 - val_loss: 2.9920 - val_accuracy: 0.7325\n",
      "Epoch 217/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.1138 - accuracy: 0.9505 - val_loss: 3.1153 - val_accuracy: 0.6675\n",
      "Epoch 218/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1338 - accuracy: 0.9448 - val_loss: 3.2353 - val_accuracy: 0.6623\n",
      "Epoch 219/500\n",
      "526/526 [==============================] - 0s 840us/step - loss: 0.1189 - accuracy: 0.9458 - val_loss: 3.3477 - val_accuracy: 0.6935\n",
      "Epoch 220/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.1327 - accuracy: 0.9420 - val_loss: 2.9783 - val_accuracy: 0.7195\n",
      "Epoch 221/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.1153 - accuracy: 0.9531 - val_loss: 2.6749 - val_accuracy: 0.7091\n",
      "Epoch 222/500\n",
      "526/526 [==============================] - 0s 831us/step - loss: 0.1205 - accuracy: 0.9451 - val_loss: 2.9431 - val_accuracy: 0.7195\n",
      "Epoch 223/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1122 - accuracy: 0.9531 - val_loss: 2.9956 - val_accuracy: 0.6961\n",
      "Epoch 224/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1204 - accuracy: 0.9474 - val_loss: 3.1454 - val_accuracy: 0.7117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.1191 - accuracy: 0.9477 - val_loss: 2.9674 - val_accuracy: 0.6805\n",
      "Epoch 226/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1206 - accuracy: 0.9518 - val_loss: 3.1345 - val_accuracy: 0.6935\n",
      "Epoch 227/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1206 - accuracy: 0.9464 - val_loss: 3.1876 - val_accuracy: 0.7143\n",
      "Epoch 228/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.1160 - accuracy: 0.9521 - val_loss: 2.9885 - val_accuracy: 0.7247\n",
      "Epoch 229/500\n",
      "526/526 [==============================] - 0s 807us/step - loss: 0.1098 - accuracy: 0.9486 - val_loss: 3.1805 - val_accuracy: 0.7195\n",
      "Epoch 230/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.1092 - accuracy: 0.9518 - val_loss: 3.1527 - val_accuracy: 0.7247\n",
      "Epoch 231/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1166 - accuracy: 0.9486 - val_loss: 3.1915 - val_accuracy: 0.7039\n",
      "Epoch 232/500\n",
      "526/526 [==============================] - 0s 813us/step - loss: 0.1307 - accuracy: 0.9477 - val_loss: 2.9210 - val_accuracy: 0.7039\n",
      "Epoch 233/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1141 - accuracy: 0.9524 - val_loss: 3.0326 - val_accuracy: 0.6831\n",
      "Epoch 234/500\n",
      "526/526 [==============================] - 0s 796us/step - loss: 0.1195 - accuracy: 0.9489 - val_loss: 2.9135 - val_accuracy: 0.7377\n",
      "Epoch 235/500\n",
      "526/526 [==============================] - 0s 804us/step - loss: 0.1105 - accuracy: 0.9515 - val_loss: 2.9559 - val_accuracy: 0.7351\n",
      "Epoch 236/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.1318 - accuracy: 0.9445 - val_loss: 3.0300 - val_accuracy: 0.7195\n",
      "Epoch 237/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.1134 - accuracy: 0.9508 - val_loss: 3.0302 - val_accuracy: 0.7247\n",
      "Epoch 238/500\n",
      "526/526 [==============================] - 0s 800us/step - loss: 0.1069 - accuracy: 0.9496 - val_loss: 2.9698 - val_accuracy: 0.7117\n",
      "Epoch 239/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.1115 - accuracy: 0.9527 - val_loss: 3.1534 - val_accuracy: 0.7039\n",
      "Epoch 240/500\n",
      "526/526 [==============================] - 0s 804us/step - loss: 0.1206 - accuracy: 0.9464 - val_loss: 2.8843 - val_accuracy: 0.7247\n",
      "Epoch 241/500\n",
      "526/526 [==============================] - 0s 796us/step - loss: 0.1287 - accuracy: 0.9483 - val_loss: 2.9174 - val_accuracy: 0.7065\n",
      "Epoch 242/500\n",
      "526/526 [==============================] - 0s 813us/step - loss: 0.1277 - accuracy: 0.9448 - val_loss: 2.9920 - val_accuracy: 0.7091\n",
      "Epoch 243/500\n",
      "526/526 [==============================] - 0s 802us/step - loss: 0.0993 - accuracy: 0.9537 - val_loss: 3.2130 - val_accuracy: 0.6883\n",
      "Epoch 244/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.1179 - accuracy: 0.9477 - val_loss: 2.7638 - val_accuracy: 0.7325\n",
      "Epoch 245/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.1333 - accuracy: 0.9435 - val_loss: 2.9496 - val_accuracy: 0.6857\n",
      "Epoch 246/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.1038 - accuracy: 0.9521 - val_loss: 3.1160 - val_accuracy: 0.7117\n",
      "Epoch 247/500\n",
      "526/526 [==============================] - 0s 804us/step - loss: 0.1085 - accuracy: 0.9537 - val_loss: 2.8770 - val_accuracy: 0.7221\n",
      "Epoch 248/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.1110 - accuracy: 0.9518 - val_loss: 3.0105 - val_accuracy: 0.7195\n",
      "Epoch 249/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1146 - accuracy: 0.9508 - val_loss: 2.8201 - val_accuracy: 0.7455\n",
      "Epoch 250/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.0999 - accuracy: 0.9556 - val_loss: 3.0884 - val_accuracy: 0.7325\n",
      "Epoch 251/500\n",
      "526/526 [==============================] - 0s 807us/step - loss: 0.1112 - accuracy: 0.9502 - val_loss: 2.9568 - val_accuracy: 0.7325\n",
      "Epoch 252/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1186 - accuracy: 0.9521 - val_loss: 2.9828 - val_accuracy: 0.7299\n",
      "Epoch 253/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.1111 - accuracy: 0.9550 - val_loss: 2.9266 - val_accuracy: 0.7273\n",
      "Epoch 254/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.0961 - accuracy: 0.9562 - val_loss: 3.1480 - val_accuracy: 0.7273\n",
      "Epoch 255/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.1160 - accuracy: 0.9534 - val_loss: 3.0805 - val_accuracy: 0.6909\n",
      "Epoch 256/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.1032 - accuracy: 0.9581 - val_loss: 3.0016 - val_accuracy: 0.7195\n",
      "Epoch 257/500\n",
      "526/526 [==============================] - 0s 813us/step - loss: 0.1158 - accuracy: 0.9537 - val_loss: 3.1711 - val_accuracy: 0.7013\n",
      "Epoch 258/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1106 - accuracy: 0.9499 - val_loss: 3.1678 - val_accuracy: 0.6805\n",
      "Epoch 259/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.1110 - accuracy: 0.9489 - val_loss: 3.1503 - val_accuracy: 0.6987\n",
      "Epoch 260/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.1102 - accuracy: 0.9534 - val_loss: 3.2870 - val_accuracy: 0.6857\n",
      "Epoch 261/500\n",
      "526/526 [==============================] - 0s 804us/step - loss: 0.1060 - accuracy: 0.9559 - val_loss: 3.4172 - val_accuracy: 0.6753\n",
      "Epoch 262/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.1056 - accuracy: 0.9562 - val_loss: 3.4225 - val_accuracy: 0.6545\n",
      "Epoch 263/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1246 - accuracy: 0.9467 - val_loss: 2.9019 - val_accuracy: 0.7247\n",
      "Epoch 264/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.1094 - accuracy: 0.9531 - val_loss: 3.0991 - val_accuracy: 0.7221\n",
      "Epoch 265/500\n",
      "526/526 [==============================] - 0s 802us/step - loss: 0.1117 - accuracy: 0.9521 - val_loss: 3.2203 - val_accuracy: 0.6935\n",
      "Epoch 266/500\n",
      "526/526 [==============================] - 0s 800us/step - loss: 0.1121 - accuracy: 0.9502 - val_loss: 3.2690 - val_accuracy: 0.7013\n",
      "Epoch 267/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.1178 - accuracy: 0.9477 - val_loss: 3.0045 - val_accuracy: 0.6961\n",
      "Epoch 268/500\n",
      "526/526 [==============================] - 0s 804us/step - loss: 0.1109 - accuracy: 0.9493 - val_loss: 3.2576 - val_accuracy: 0.6857\n",
      "Epoch 269/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0976 - accuracy: 0.9559 - val_loss: 3.0529 - val_accuracy: 0.6961\n",
      "Epoch 270/500\n",
      "526/526 [==============================] - 0s 827us/step - loss: 0.0969 - accuracy: 0.9578 - val_loss: 3.2515 - val_accuracy: 0.7039\n",
      "Epoch 271/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1324 - accuracy: 0.9480 - val_loss: 3.2394 - val_accuracy: 0.7013\n",
      "Epoch 272/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1160 - accuracy: 0.9496 - val_loss: 3.0866 - val_accuracy: 0.6909\n",
      "Epoch 273/500\n",
      "526/526 [==============================] - 0s 800us/step - loss: 0.0993 - accuracy: 0.9585 - val_loss: 2.9458 - val_accuracy: 0.7195\n",
      "Epoch 274/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.1052 - accuracy: 0.9581 - val_loss: 3.2201 - val_accuracy: 0.6857\n",
      "Epoch 275/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.0989 - accuracy: 0.9581 - val_loss: 3.3527 - val_accuracy: 0.6805\n",
      "Epoch 276/500\n",
      "526/526 [==============================] - 0s 804us/step - loss: 0.0978 - accuracy: 0.9550 - val_loss: 3.2583 - val_accuracy: 0.7169\n",
      "Epoch 277/500\n",
      "526/526 [==============================] - 0s 842us/step - loss: 0.1205 - accuracy: 0.9474 - val_loss: 3.1189 - val_accuracy: 0.7195\n",
      "Epoch 278/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.0921 - accuracy: 0.9585 - val_loss: 3.3309 - val_accuracy: 0.6831\n",
      "Epoch 279/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.1136 - accuracy: 0.9550 - val_loss: 3.1772 - val_accuracy: 0.7091\n",
      "Epoch 280/500\n",
      "526/526 [==============================] - 0s 805us/step - loss: 0.1149 - accuracy: 0.9531 - val_loss: 2.9956 - val_accuracy: 0.7299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1129 - accuracy: 0.9524 - val_loss: 3.1327 - val_accuracy: 0.6935\n",
      "Epoch 282/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.1060 - accuracy: 0.9537 - val_loss: 3.1035 - val_accuracy: 0.7247\n",
      "Epoch 283/500\n",
      "526/526 [==============================] - 0s 809us/step - loss: 0.0985 - accuracy: 0.9575 - val_loss: 3.0603 - val_accuracy: 0.7143\n",
      "Epoch 284/500\n",
      "526/526 [==============================] - 0s 804us/step - loss: 0.1196 - accuracy: 0.9508 - val_loss: 3.0768 - val_accuracy: 0.7169\n",
      "Epoch 285/500\n",
      "526/526 [==============================] - 0s 802us/step - loss: 0.1102 - accuracy: 0.9575 - val_loss: 3.2204 - val_accuracy: 0.6779\n",
      "Epoch 286/500\n",
      "526/526 [==============================] - 0s 794us/step - loss: 0.1111 - accuracy: 0.9534 - val_loss: 2.9725 - val_accuracy: 0.7039\n",
      "Epoch 287/500\n",
      "526/526 [==============================] - 0s 800us/step - loss: 0.1028 - accuracy: 0.9546 - val_loss: 3.0647 - val_accuracy: 0.7013\n",
      "Epoch 288/500\n",
      "526/526 [==============================] - 0s 804us/step - loss: 0.0922 - accuracy: 0.9616 - val_loss: 3.0553 - val_accuracy: 0.7247\n",
      "Epoch 289/500\n",
      "526/526 [==============================] - 0s 796us/step - loss: 0.1037 - accuracy: 0.9521 - val_loss: 3.2969 - val_accuracy: 0.6883\n",
      "Epoch 290/500\n",
      "526/526 [==============================] - 0s 796us/step - loss: 0.1144 - accuracy: 0.9534 - val_loss: 3.1716 - val_accuracy: 0.7247\n",
      "Epoch 291/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1041 - accuracy: 0.9578 - val_loss: 3.0274 - val_accuracy: 0.7247\n",
      "Epoch 292/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0981 - accuracy: 0.9543 - val_loss: 3.1795 - val_accuracy: 0.7013\n",
      "Epoch 293/500\n",
      "526/526 [==============================] - 0s 849us/step - loss: 0.1116 - accuracy: 0.9534 - val_loss: 2.9044 - val_accuracy: 0.7117\n",
      "Epoch 294/500\n",
      "526/526 [==============================] - 1s 979us/step - loss: 0.1084 - accuracy: 0.9565 - val_loss: 2.9434 - val_accuracy: 0.7065\n",
      "Epoch 295/500\n",
      "526/526 [==============================] - 0s 895us/step - loss: 0.1012 - accuracy: 0.9543 - val_loss: 2.9568 - val_accuracy: 0.6987\n",
      "Epoch 296/500\n",
      "526/526 [==============================] - 0s 895us/step - loss: 0.1094 - accuracy: 0.9521 - val_loss: 3.0509 - val_accuracy: 0.7195\n",
      "Epoch 297/500\n",
      "526/526 [==============================] - 0s 908us/step - loss: 0.1047 - accuracy: 0.9565 - val_loss: 2.9041 - val_accuracy: 0.7325\n",
      "Epoch 298/500\n",
      "526/526 [==============================] - 0s 873us/step - loss: 0.0991 - accuracy: 0.9575 - val_loss: 3.0330 - val_accuracy: 0.7325\n",
      "Epoch 299/500\n",
      "526/526 [==============================] - 0s 861us/step - loss: 0.0982 - accuracy: 0.9556 - val_loss: 2.9655 - val_accuracy: 0.7377\n",
      "Epoch 300/500\n",
      "526/526 [==============================] - 0s 874us/step - loss: 0.1024 - accuracy: 0.9524 - val_loss: 3.1793 - val_accuracy: 0.7039\n",
      "Epoch 301/500\n",
      "526/526 [==============================] - 0s 842us/step - loss: 0.1213 - accuracy: 0.9458 - val_loss: 2.9004 - val_accuracy: 0.7169\n",
      "Epoch 302/500\n",
      "526/526 [==============================] - 0s 863us/step - loss: 0.0935 - accuracy: 0.9638 - val_loss: 3.0689 - val_accuracy: 0.7039\n",
      "Epoch 303/500\n",
      "526/526 [==============================] - 0s 888us/step - loss: 0.1015 - accuracy: 0.9569 - val_loss: 3.3932 - val_accuracy: 0.6727\n",
      "Epoch 304/500\n",
      "526/526 [==============================] - 0s 870us/step - loss: 0.1057 - accuracy: 0.9534 - val_loss: 3.3236 - val_accuracy: 0.6805\n",
      "Epoch 305/500\n",
      "526/526 [==============================] - 0s 865us/step - loss: 0.1023 - accuracy: 0.9556 - val_loss: 3.3077 - val_accuracy: 0.7091\n",
      "Epoch 306/500\n",
      "526/526 [==============================] - 0s 871us/step - loss: 0.0981 - accuracy: 0.9531 - val_loss: 3.2481 - val_accuracy: 0.6935\n",
      "Epoch 307/500\n",
      "526/526 [==============================] - 0s 876us/step - loss: 0.1167 - accuracy: 0.9499 - val_loss: 3.2176 - val_accuracy: 0.7117\n",
      "Epoch 308/500\n",
      "526/526 [==============================] - 0s 846us/step - loss: 0.1204 - accuracy: 0.9474 - val_loss: 3.2053 - val_accuracy: 0.6727\n",
      "Epoch 309/500\n",
      "526/526 [==============================] - 0s 873us/step - loss: 0.0853 - accuracy: 0.9635 - val_loss: 3.2753 - val_accuracy: 0.7117\n",
      "Epoch 310/500\n",
      "526/526 [==============================] - 0s 926us/step - loss: 0.0931 - accuracy: 0.9562 - val_loss: 3.2614 - val_accuracy: 0.7273\n",
      "Epoch 311/500\n",
      "526/526 [==============================] - 0s 857us/step - loss: 0.1194 - accuracy: 0.9474 - val_loss: 3.1764 - val_accuracy: 0.7039\n",
      "Epoch 312/500\n",
      "526/526 [==============================] - 0s 842us/step - loss: 0.1114 - accuracy: 0.9540 - val_loss: 3.0224 - val_accuracy: 0.7013\n",
      "Epoch 313/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.1142 - accuracy: 0.9483 - val_loss: 3.1441 - val_accuracy: 0.7169\n",
      "Epoch 314/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.0999 - accuracy: 0.9537 - val_loss: 3.2623 - val_accuracy: 0.6935\n",
      "Epoch 315/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.0994 - accuracy: 0.9559 - val_loss: 3.2276 - val_accuracy: 0.6987\n",
      "Epoch 316/500\n",
      "526/526 [==============================] - 0s 827us/step - loss: 0.1212 - accuracy: 0.9496 - val_loss: 3.3584 - val_accuracy: 0.6857\n",
      "Epoch 317/500\n",
      "526/526 [==============================] - 0s 818us/step - loss: 0.0899 - accuracy: 0.9619 - val_loss: 3.4112 - val_accuracy: 0.7039\n",
      "Epoch 318/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.0937 - accuracy: 0.9604 - val_loss: 3.4825 - val_accuracy: 0.6935\n",
      "Epoch 319/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1088 - accuracy: 0.9553 - val_loss: 3.4366 - val_accuracy: 0.6753\n",
      "Epoch 320/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.0958 - accuracy: 0.9578 - val_loss: 3.3873 - val_accuracy: 0.6623\n",
      "Epoch 321/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.1024 - accuracy: 0.9527 - val_loss: 3.5293 - val_accuracy: 0.6260\n",
      "Epoch 322/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1092 - accuracy: 0.9540 - val_loss: 3.0852 - val_accuracy: 0.7247\n",
      "Epoch 323/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1107 - accuracy: 0.9518 - val_loss: 3.1272 - val_accuracy: 0.6857\n",
      "Epoch 324/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.1029 - accuracy: 0.9575 - val_loss: 3.1953 - val_accuracy: 0.6961\n",
      "Epoch 325/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.0915 - accuracy: 0.9588 - val_loss: 3.1798 - val_accuracy: 0.6961\n",
      "Epoch 326/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.0992 - accuracy: 0.9578 - val_loss: 3.0946 - val_accuracy: 0.7221\n",
      "Epoch 327/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.0937 - accuracy: 0.9594 - val_loss: 3.2604 - val_accuracy: 0.6987\n",
      "Epoch 328/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.1133 - accuracy: 0.9543 - val_loss: 3.4044 - val_accuracy: 0.6416\n",
      "Epoch 329/500\n",
      "526/526 [==============================] - 0s 829us/step - loss: 0.1026 - accuracy: 0.9572 - val_loss: 3.0796 - val_accuracy: 0.6649\n",
      "Epoch 330/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.0985 - accuracy: 0.9553 - val_loss: 2.9131 - val_accuracy: 0.7325\n",
      "Epoch 331/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.1037 - accuracy: 0.9512 - val_loss: 3.0561 - val_accuracy: 0.6909\n",
      "Epoch 332/500\n",
      "526/526 [==============================] - 0s 834us/step - loss: 0.0859 - accuracy: 0.9591 - val_loss: 3.1476 - val_accuracy: 0.7247\n",
      "Epoch 333/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.0913 - accuracy: 0.9610 - val_loss: 3.1238 - val_accuracy: 0.6831\n",
      "Epoch 334/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.0991 - accuracy: 0.9578 - val_loss: 3.1917 - val_accuracy: 0.7117\n",
      "Epoch 335/500\n",
      "526/526 [==============================] - 0s 846us/step - loss: 0.1058 - accuracy: 0.9531 - val_loss: 3.1285 - val_accuracy: 0.7117\n",
      "Epoch 336/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.1023 - accuracy: 0.9550 - val_loss: 2.9668 - val_accuracy: 0.7039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.0907 - accuracy: 0.9591 - val_loss: 3.2732 - val_accuracy: 0.6857\n",
      "Epoch 338/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1000 - accuracy: 0.9565 - val_loss: 3.1934 - val_accuracy: 0.7013\n",
      "Epoch 339/500\n",
      "526/526 [==============================] - 0s 802us/step - loss: 0.0989 - accuracy: 0.9607 - val_loss: 3.3482 - val_accuracy: 0.6649\n",
      "Epoch 340/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1099 - accuracy: 0.9546 - val_loss: 3.1564 - val_accuracy: 0.6727\n",
      "Epoch 341/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.0975 - accuracy: 0.9540 - val_loss: 3.2861 - val_accuracy: 0.7065\n",
      "Epoch 342/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.0951 - accuracy: 0.9594 - val_loss: 3.4328 - val_accuracy: 0.7143\n",
      "Epoch 343/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1015 - accuracy: 0.9556 - val_loss: 3.3758 - val_accuracy: 0.6961\n",
      "Epoch 344/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0974 - accuracy: 0.9534 - val_loss: 3.3148 - val_accuracy: 0.6961\n",
      "Epoch 345/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1113 - accuracy: 0.9540 - val_loss: 3.1666 - val_accuracy: 0.6623\n",
      "Epoch 346/500\n",
      "526/526 [==============================] - 0s 831us/step - loss: 0.0822 - accuracy: 0.9613 - val_loss: 3.4472 - val_accuracy: 0.6961\n",
      "Epoch 347/500\n",
      "526/526 [==============================] - 0s 843us/step - loss: 0.1161 - accuracy: 0.9534 - val_loss: 3.0326 - val_accuracy: 0.6987\n",
      "Epoch 348/500\n",
      "526/526 [==============================] - 0s 828us/step - loss: 0.0989 - accuracy: 0.9572 - val_loss: 3.2376 - val_accuracy: 0.6961\n",
      "Epoch 349/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.0878 - accuracy: 0.9619 - val_loss: 3.4610 - val_accuracy: 0.6779\n",
      "Epoch 350/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.1011 - accuracy: 0.9562 - val_loss: 3.4035 - val_accuracy: 0.6727\n",
      "Epoch 351/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.1083 - accuracy: 0.9556 - val_loss: 3.2312 - val_accuracy: 0.7039\n",
      "Epoch 352/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.0860 - accuracy: 0.9607 - val_loss: 3.1967 - val_accuracy: 0.7195\n",
      "Epoch 353/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.1029 - accuracy: 0.9600 - val_loss: 3.1881 - val_accuracy: 0.7195\n",
      "Epoch 354/500\n",
      "526/526 [==============================] - 0s 813us/step - loss: 0.0859 - accuracy: 0.9613 - val_loss: 3.3381 - val_accuracy: 0.6857\n",
      "Epoch 355/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.1076 - accuracy: 0.9543 - val_loss: 3.2629 - val_accuracy: 0.7143\n",
      "Epoch 356/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.1036 - accuracy: 0.9527 - val_loss: 3.4282 - val_accuracy: 0.6857\n",
      "Epoch 357/500\n",
      "526/526 [==============================] - 0s 807us/step - loss: 0.1028 - accuracy: 0.9572 - val_loss: 3.2703 - val_accuracy: 0.7039\n",
      "Epoch 358/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0972 - accuracy: 0.9619 - val_loss: 3.0570 - val_accuracy: 0.7221\n",
      "Epoch 359/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0988 - accuracy: 0.9588 - val_loss: 3.4193 - val_accuracy: 0.6831\n",
      "Epoch 360/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.0868 - accuracy: 0.9619 - val_loss: 3.2709 - val_accuracy: 0.7039\n",
      "Epoch 361/500\n",
      "526/526 [==============================] - 0s 813us/step - loss: 0.0816 - accuracy: 0.9635 - val_loss: 3.3539 - val_accuracy: 0.7039\n",
      "Epoch 362/500\n",
      "526/526 [==============================] - 0s 827us/step - loss: 0.1073 - accuracy: 0.9553 - val_loss: 3.2056 - val_accuracy: 0.7221\n",
      "Epoch 363/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.0961 - accuracy: 0.9581 - val_loss: 3.2687 - val_accuracy: 0.6909\n",
      "Epoch 364/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.1009 - accuracy: 0.9562 - val_loss: 3.1463 - val_accuracy: 0.7169\n",
      "Epoch 365/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.0862 - accuracy: 0.9635 - val_loss: 3.2259 - val_accuracy: 0.7351\n",
      "Epoch 366/500\n",
      "526/526 [==============================] - 0s 800us/step - loss: 0.0954 - accuracy: 0.9565 - val_loss: 3.1793 - val_accuracy: 0.7091\n",
      "Epoch 367/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.0951 - accuracy: 0.9581 - val_loss: 3.1534 - val_accuracy: 0.7169\n",
      "Epoch 368/500\n",
      "526/526 [==============================] - 0s 796us/step - loss: 0.0831 - accuracy: 0.9594 - val_loss: 3.0461 - val_accuracy: 0.7117\n",
      "Epoch 369/500\n",
      "526/526 [==============================] - 0s 798us/step - loss: 0.0982 - accuracy: 0.9578 - val_loss: 3.4527 - val_accuracy: 0.6727\n",
      "Epoch 370/500\n",
      "526/526 [==============================] - 0s 798us/step - loss: 0.1021 - accuracy: 0.9550 - val_loss: 3.3523 - val_accuracy: 0.7169\n",
      "Epoch 371/500\n",
      "526/526 [==============================] - 0s 777us/step - loss: 0.0943 - accuracy: 0.9569 - val_loss: 3.3353 - val_accuracy: 0.7273\n",
      "Epoch 372/500\n",
      "526/526 [==============================] - 0s 787us/step - loss: 0.0875 - accuracy: 0.9619 - val_loss: 3.3049 - val_accuracy: 0.7403\n",
      "Epoch 373/500\n",
      "526/526 [==============================] - 0s 787us/step - loss: 0.0917 - accuracy: 0.9594 - val_loss: 3.3992 - val_accuracy: 0.7013\n",
      "Epoch 374/500\n",
      "526/526 [==============================] - 0s 789us/step - loss: 0.0968 - accuracy: 0.9578 - val_loss: 3.5896 - val_accuracy: 0.7039\n",
      "Epoch 375/500\n",
      "526/526 [==============================] - 0s 789us/step - loss: 0.0993 - accuracy: 0.9543 - val_loss: 3.4368 - val_accuracy: 0.6961\n",
      "Epoch 376/500\n",
      "526/526 [==============================] - 0s 784us/step - loss: 0.0896 - accuracy: 0.9591 - val_loss: 3.5600 - val_accuracy: 0.6571\n",
      "Epoch 377/500\n",
      "526/526 [==============================] - 0s 791us/step - loss: 0.0956 - accuracy: 0.9585 - val_loss: 3.6159 - val_accuracy: 0.6805\n",
      "Epoch 378/500\n",
      "526/526 [==============================] - 0s 777us/step - loss: 0.0883 - accuracy: 0.9619 - val_loss: 3.4021 - val_accuracy: 0.7013\n",
      "Epoch 379/500\n",
      "526/526 [==============================] - 0s 777us/step - loss: 0.0940 - accuracy: 0.9597 - val_loss: 3.2270 - val_accuracy: 0.6961\n",
      "Epoch 380/500\n",
      "526/526 [==============================] - 0s 777us/step - loss: 0.0896 - accuracy: 0.9588 - val_loss: 3.3624 - val_accuracy: 0.6935\n",
      "Epoch 381/500\n",
      "526/526 [==============================] - 0s 791us/step - loss: 0.0956 - accuracy: 0.9565 - val_loss: 3.4768 - val_accuracy: 0.6909\n",
      "Epoch 382/500\n",
      "526/526 [==============================] - 0s 787us/step - loss: 0.0957 - accuracy: 0.9578 - val_loss: 3.5864 - val_accuracy: 0.7039\n",
      "Epoch 383/500\n",
      "526/526 [==============================] - 0s 787us/step - loss: 0.0840 - accuracy: 0.9642 - val_loss: 3.3881 - val_accuracy: 0.7351\n",
      "Epoch 384/500\n",
      "526/526 [==============================] - 0s 798us/step - loss: 0.1063 - accuracy: 0.9559 - val_loss: 3.4335 - val_accuracy: 0.7247\n",
      "Epoch 385/500\n",
      "526/526 [==============================] - 0s 788us/step - loss: 0.0822 - accuracy: 0.9638 - val_loss: 3.5084 - val_accuracy: 0.7065\n",
      "Epoch 386/500\n",
      "526/526 [==============================] - 0s 794us/step - loss: 0.0987 - accuracy: 0.9559 - val_loss: 3.0309 - val_accuracy: 0.7247\n",
      "Epoch 387/500\n",
      "526/526 [==============================] - 0s 784us/step - loss: 0.0810 - accuracy: 0.9670 - val_loss: 3.0977 - val_accuracy: 0.7195\n",
      "Epoch 388/500\n",
      "526/526 [==============================] - 0s 777us/step - loss: 0.1011 - accuracy: 0.9559 - val_loss: 3.1836 - val_accuracy: 0.7039\n",
      "Epoch 389/500\n",
      "526/526 [==============================] - 0s 791us/step - loss: 0.0978 - accuracy: 0.9550 - val_loss: 3.2485 - val_accuracy: 0.7143\n",
      "Epoch 390/500\n",
      "526/526 [==============================] - 0s 794us/step - loss: 0.0914 - accuracy: 0.9572 - val_loss: 3.3127 - val_accuracy: 0.6909\n",
      "Epoch 391/500\n",
      "526/526 [==============================] - 0s 789us/step - loss: 0.0896 - accuracy: 0.9645 - val_loss: 3.3323 - val_accuracy: 0.7247\n",
      "Epoch 392/500\n",
      "526/526 [==============================] - 0s 785us/step - loss: 0.1054 - accuracy: 0.9588 - val_loss: 3.1534 - val_accuracy: 0.7091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/500\n",
      "526/526 [==============================] - 0s 784us/step - loss: 0.0907 - accuracy: 0.9597 - val_loss: 3.3511 - val_accuracy: 0.6753\n",
      "Epoch 394/500\n",
      "526/526 [==============================] - 0s 777us/step - loss: 0.0933 - accuracy: 0.9585 - val_loss: 3.3065 - val_accuracy: 0.6883\n",
      "Epoch 395/500\n",
      "526/526 [==============================] - 0s 785us/step - loss: 0.0836 - accuracy: 0.9648 - val_loss: 3.2083 - val_accuracy: 0.7065\n",
      "Epoch 396/500\n",
      "526/526 [==============================] - 0s 792us/step - loss: 0.0981 - accuracy: 0.9591 - val_loss: 3.2653 - val_accuracy: 0.7039\n",
      "Epoch 397/500\n",
      "526/526 [==============================] - 0s 787us/step - loss: 0.0830 - accuracy: 0.9651 - val_loss: 3.2895 - val_accuracy: 0.7221\n",
      "Epoch 398/500\n",
      "526/526 [==============================] - 0s 798us/step - loss: 0.0995 - accuracy: 0.9588 - val_loss: 3.4206 - val_accuracy: 0.6831\n",
      "Epoch 399/500\n",
      "526/526 [==============================] - 0s 787us/step - loss: 0.0901 - accuracy: 0.9600 - val_loss: 3.2382 - val_accuracy: 0.6987\n",
      "Epoch 400/500\n",
      "526/526 [==============================] - 0s 794us/step - loss: 0.0999 - accuracy: 0.9556 - val_loss: 3.3163 - val_accuracy: 0.7039\n",
      "Epoch 401/500\n",
      "526/526 [==============================] - 0s 796us/step - loss: 0.0850 - accuracy: 0.9607 - val_loss: 3.2885 - val_accuracy: 0.7091\n",
      "Epoch 402/500\n",
      "526/526 [==============================] - 0s 793us/step - loss: 0.0916 - accuracy: 0.9613 - val_loss: 3.3190 - val_accuracy: 0.7039\n",
      "Epoch 403/500\n",
      "526/526 [==============================] - 0s 781us/step - loss: 0.0853 - accuracy: 0.9629 - val_loss: 3.0117 - val_accuracy: 0.7377\n",
      "Epoch 404/500\n",
      "526/526 [==============================] - 0s 791us/step - loss: 0.0963 - accuracy: 0.9569 - val_loss: 3.5768 - val_accuracy: 0.6779\n",
      "Epoch 405/500\n",
      "526/526 [==============================] - 0s 804us/step - loss: 0.1000 - accuracy: 0.9597 - val_loss: 3.0706 - val_accuracy: 0.7299\n",
      "Epoch 406/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.0832 - accuracy: 0.9664 - val_loss: 3.2689 - val_accuracy: 0.7377\n",
      "Epoch 407/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.0903 - accuracy: 0.9585 - val_loss: 3.3965 - val_accuracy: 0.7039\n",
      "Epoch 408/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0979 - accuracy: 0.9572 - val_loss: 3.4704 - val_accuracy: 0.7065\n",
      "Epoch 409/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0804 - accuracy: 0.9648 - val_loss: 3.1938 - val_accuracy: 0.7351\n",
      "Epoch 410/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0940 - accuracy: 0.9572 - val_loss: 3.3667 - val_accuracy: 0.7013\n",
      "Epoch 411/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.0810 - accuracy: 0.9629 - val_loss: 3.3996 - val_accuracy: 0.6935\n",
      "Epoch 412/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.0984 - accuracy: 0.9569 - val_loss: 3.5093 - val_accuracy: 0.7091\n",
      "Epoch 413/500\n",
      "526/526 [==============================] - 0s 822us/step - loss: 0.0968 - accuracy: 0.9565 - val_loss: 3.2900 - val_accuracy: 0.7247\n",
      "Epoch 414/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.0889 - accuracy: 0.9597 - val_loss: 3.2745 - val_accuracy: 0.7013\n",
      "Epoch 415/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.0851 - accuracy: 0.9607 - val_loss: 3.2746 - val_accuracy: 0.7117\n",
      "Epoch 416/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.0897 - accuracy: 0.9626 - val_loss: 3.4094 - val_accuracy: 0.6857\n",
      "Epoch 417/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.0851 - accuracy: 0.9607 - val_loss: 3.4134 - val_accuracy: 0.7247\n",
      "Epoch 418/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0870 - accuracy: 0.9607 - val_loss: 3.3295 - val_accuracy: 0.7195\n",
      "Epoch 419/500\n",
      "526/526 [==============================] - 0s 811us/step - loss: 0.1057 - accuracy: 0.9585 - val_loss: 3.5476 - val_accuracy: 0.6753\n",
      "Epoch 420/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0854 - accuracy: 0.9591 - val_loss: 3.2761 - val_accuracy: 0.7169\n",
      "Epoch 421/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.0887 - accuracy: 0.9616 - val_loss: 3.4916 - val_accuracy: 0.6649\n",
      "Epoch 422/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.0775 - accuracy: 0.9654 - val_loss: 3.5108 - val_accuracy: 0.7039\n",
      "Epoch 423/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.0987 - accuracy: 0.9610 - val_loss: 3.4105 - val_accuracy: 0.7013\n",
      "Epoch 424/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.0968 - accuracy: 0.9610 - val_loss: 3.1641 - val_accuracy: 0.7195\n",
      "Epoch 425/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.0821 - accuracy: 0.9648 - val_loss: 3.3555 - val_accuracy: 0.6987\n",
      "Epoch 426/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0852 - accuracy: 0.9623 - val_loss: 3.3719 - val_accuracy: 0.7247\n",
      "Epoch 427/500\n",
      "526/526 [==============================] - 0s 831us/step - loss: 0.0929 - accuracy: 0.9607 - val_loss: 3.3517 - val_accuracy: 0.7299\n",
      "Epoch 428/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.0879 - accuracy: 0.9642 - val_loss: 3.4395 - val_accuracy: 0.7195\n",
      "Epoch 429/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.0852 - accuracy: 0.9594 - val_loss: 3.5651 - val_accuracy: 0.7117\n",
      "Epoch 430/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.0915 - accuracy: 0.9619 - val_loss: 3.4691 - val_accuracy: 0.7325\n",
      "Epoch 431/500\n",
      "526/526 [==============================] - 0s 818us/step - loss: 0.0981 - accuracy: 0.9572 - val_loss: 3.6074 - val_accuracy: 0.6987\n",
      "Epoch 432/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.0873 - accuracy: 0.9604 - val_loss: 3.7779 - val_accuracy: 0.6779\n",
      "Epoch 433/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.0772 - accuracy: 0.9642 - val_loss: 3.5316 - val_accuracy: 0.7117\n",
      "Epoch 434/500\n",
      "526/526 [==============================] - 0s 831us/step - loss: 0.0807 - accuracy: 0.9670 - val_loss: 3.6935 - val_accuracy: 0.6857\n",
      "Epoch 435/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.1043 - accuracy: 0.9588 - val_loss: 3.4241 - val_accuracy: 0.7091\n",
      "Epoch 436/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.0887 - accuracy: 0.9613 - val_loss: 3.4274 - val_accuracy: 0.7091\n",
      "Epoch 437/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0949 - accuracy: 0.9600 - val_loss: 3.6943 - val_accuracy: 0.6935\n",
      "Epoch 438/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.0924 - accuracy: 0.9604 - val_loss: 3.5093 - val_accuracy: 0.6961\n",
      "Epoch 439/500\n",
      "526/526 [==============================] - 0s 820us/step - loss: 0.0973 - accuracy: 0.9575 - val_loss: 3.4418 - val_accuracy: 0.7065\n",
      "Epoch 440/500\n",
      "526/526 [==============================] - 0s 829us/step - loss: 0.0898 - accuracy: 0.9604 - val_loss: 3.4880 - val_accuracy: 0.7013\n",
      "Epoch 441/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.0921 - accuracy: 0.9610 - val_loss: 3.3706 - val_accuracy: 0.6805\n",
      "Epoch 442/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0824 - accuracy: 0.9638 - val_loss: 3.5660 - val_accuracy: 0.6727\n",
      "Epoch 443/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.0882 - accuracy: 0.9613 - val_loss: 3.4280 - val_accuracy: 0.7013\n",
      "Epoch 444/500\n",
      "526/526 [==============================] - 0s 814us/step - loss: 0.0825 - accuracy: 0.9645 - val_loss: 3.5767 - val_accuracy: 0.7065\n",
      "Epoch 445/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.0771 - accuracy: 0.9635 - val_loss: 3.5948 - val_accuracy: 0.7013\n",
      "Epoch 446/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.0843 - accuracy: 0.9648 - val_loss: 3.4655 - val_accuracy: 0.7143\n",
      "Epoch 447/500\n",
      "526/526 [==============================] - 0s 831us/step - loss: 0.0887 - accuracy: 0.9619 - val_loss: 3.6015 - val_accuracy: 0.7351\n",
      "Epoch 448/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.1046 - accuracy: 0.9562 - val_loss: 3.3179 - val_accuracy: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.0835 - accuracy: 0.9619 - val_loss: 3.5312 - val_accuracy: 0.6961\n",
      "Epoch 450/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.0917 - accuracy: 0.9607 - val_loss: 3.6975 - val_accuracy: 0.6701\n",
      "Epoch 451/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.0833 - accuracy: 0.9638 - val_loss: 3.3278 - val_accuracy: 0.7273\n",
      "Epoch 452/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.0953 - accuracy: 0.9597 - val_loss: 3.6609 - val_accuracy: 0.6675\n",
      "Epoch 453/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.0775 - accuracy: 0.9664 - val_loss: 3.3952 - val_accuracy: 0.7091\n",
      "Epoch 454/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.0895 - accuracy: 0.9600 - val_loss: 3.3522 - val_accuracy: 0.7299\n",
      "Epoch 455/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.0869 - accuracy: 0.9594 - val_loss: 3.9000 - val_accuracy: 0.6857\n",
      "Epoch 456/500\n",
      "526/526 [==============================] - 0s 819us/step - loss: 0.0970 - accuracy: 0.9613 - val_loss: 3.5003 - val_accuracy: 0.7247\n",
      "Epoch 457/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0789 - accuracy: 0.9632 - val_loss: 3.3959 - val_accuracy: 0.7065\n",
      "Epoch 458/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.1020 - accuracy: 0.9550 - val_loss: 3.6658 - val_accuracy: 0.7221\n",
      "Epoch 459/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.0778 - accuracy: 0.9632 - val_loss: 3.4312 - val_accuracy: 0.7013\n",
      "Epoch 460/500\n",
      "526/526 [==============================] - 0s 813us/step - loss: 0.0756 - accuracy: 0.9683 - val_loss: 3.3589 - val_accuracy: 0.7403\n",
      "Epoch 461/500\n",
      "526/526 [==============================] - 0s 829us/step - loss: 0.1048 - accuracy: 0.9610 - val_loss: 3.7833 - val_accuracy: 0.7039\n",
      "Epoch 462/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0794 - accuracy: 0.9645 - val_loss: 3.5594 - val_accuracy: 0.7169\n",
      "Epoch 463/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0976 - accuracy: 0.9581 - val_loss: 3.4290 - val_accuracy: 0.6909\n",
      "Epoch 464/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.0867 - accuracy: 0.9597 - val_loss: 3.6648 - val_accuracy: 0.6987\n",
      "Epoch 465/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.0798 - accuracy: 0.9626 - val_loss: 3.7026 - val_accuracy: 0.6779\n",
      "Epoch 466/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.0867 - accuracy: 0.9629 - val_loss: 3.8215 - val_accuracy: 0.6727\n",
      "Epoch 467/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.0867 - accuracy: 0.9632 - val_loss: 3.7163 - val_accuracy: 0.6805\n",
      "Epoch 468/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0941 - accuracy: 0.9597 - val_loss: 3.6885 - val_accuracy: 0.6857\n",
      "Epoch 469/500\n",
      "526/526 [==============================] - 0s 817us/step - loss: 0.1047 - accuracy: 0.9540 - val_loss: 3.4950 - val_accuracy: 0.7065\n",
      "Epoch 470/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.0792 - accuracy: 0.9670 - val_loss: 3.3757 - val_accuracy: 0.7299\n",
      "Epoch 471/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0767 - accuracy: 0.9638 - val_loss: 3.6060 - val_accuracy: 0.7039\n",
      "Epoch 472/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.0837 - accuracy: 0.9632 - val_loss: 3.4772 - val_accuracy: 0.7299\n",
      "Epoch 473/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.0923 - accuracy: 0.9619 - val_loss: 3.4385 - val_accuracy: 0.7325\n",
      "Epoch 474/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.0896 - accuracy: 0.9623 - val_loss: 3.5485 - val_accuracy: 0.7169\n",
      "Epoch 475/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.0747 - accuracy: 0.9670 - val_loss: 3.4423 - val_accuracy: 0.6961\n",
      "Epoch 476/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.0985 - accuracy: 0.9594 - val_loss: 3.7457 - val_accuracy: 0.6675\n",
      "Epoch 477/500\n",
      "526/526 [==============================] - 0s 806us/step - loss: 0.0872 - accuracy: 0.9616 - val_loss: 3.4882 - val_accuracy: 0.7039\n",
      "Epoch 478/500\n",
      "526/526 [==============================] - 0s 803us/step - loss: 0.0795 - accuracy: 0.9638 - val_loss: 3.5380 - val_accuracy: 0.7091\n",
      "Epoch 479/500\n",
      "526/526 [==============================] - 0s 794us/step - loss: 0.0895 - accuracy: 0.9600 - val_loss: 3.7228 - val_accuracy: 0.6753\n",
      "Epoch 480/500\n",
      "526/526 [==============================] - 0s 802us/step - loss: 0.0819 - accuracy: 0.9619 - val_loss: 3.6148 - val_accuracy: 0.7221\n",
      "Epoch 481/500\n",
      "526/526 [==============================] - 0s 802us/step - loss: 0.0803 - accuracy: 0.9629 - val_loss: 3.8594 - val_accuracy: 0.6909\n",
      "Epoch 482/500\n",
      "526/526 [==============================] - 0s 811us/step - loss: 0.0879 - accuracy: 0.9635 - val_loss: 3.4250 - val_accuracy: 0.7169\n",
      "Epoch 483/500\n",
      "526/526 [==============================] - 0s 802us/step - loss: 0.0790 - accuracy: 0.9632 - val_loss: 3.7946 - val_accuracy: 0.6935\n",
      "Epoch 484/500\n",
      "526/526 [==============================] - 0s 808us/step - loss: 0.0925 - accuracy: 0.9635 - val_loss: 3.7385 - val_accuracy: 0.7013\n",
      "Epoch 485/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.0847 - accuracy: 0.9638 - val_loss: 4.0201 - val_accuracy: 0.6571\n",
      "Epoch 486/500\n",
      "526/526 [==============================] - 0s 804us/step - loss: 0.0833 - accuracy: 0.9645 - val_loss: 3.8424 - val_accuracy: 0.6649\n",
      "Epoch 487/500\n",
      "526/526 [==============================] - 0s 793us/step - loss: 0.1037 - accuracy: 0.9569 - val_loss: 3.4639 - val_accuracy: 0.7117\n",
      "Epoch 488/500\n",
      "526/526 [==============================] - 0s 798us/step - loss: 0.0810 - accuracy: 0.9670 - val_loss: 3.3596 - val_accuracy: 0.7169\n",
      "Epoch 489/500\n",
      "526/526 [==============================] - 0s 796us/step - loss: 0.0774 - accuracy: 0.9651 - val_loss: 3.6792 - val_accuracy: 0.6909\n",
      "Epoch 490/500\n",
      "526/526 [==============================] - 0s 827us/step - loss: 0.0815 - accuracy: 0.9654 - val_loss: 3.6994 - val_accuracy: 0.7013\n",
      "Epoch 491/500\n",
      "526/526 [==============================] - 0s 825us/step - loss: 0.0745 - accuracy: 0.9661 - val_loss: 3.9162 - val_accuracy: 0.6416\n",
      "Epoch 492/500\n",
      "526/526 [==============================] - 0s 812us/step - loss: 0.0963 - accuracy: 0.9610 - val_loss: 3.6963 - val_accuracy: 0.6883\n",
      "Epoch 493/500\n",
      "526/526 [==============================] - 0s 798us/step - loss: 0.0806 - accuracy: 0.9626 - val_loss: 3.8007 - val_accuracy: 0.6935\n",
      "Epoch 494/500\n",
      "526/526 [==============================] - 0s 800us/step - loss: 0.0847 - accuracy: 0.9626 - val_loss: 3.5875 - val_accuracy: 0.7143\n",
      "Epoch 495/500\n",
      "526/526 [==============================] - 0s 821us/step - loss: 0.0956 - accuracy: 0.9604 - val_loss: 3.3814 - val_accuracy: 0.6987\n",
      "Epoch 496/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0852 - accuracy: 0.9648 - val_loss: 3.3460 - val_accuracy: 0.7273\n",
      "Epoch 497/500\n",
      "526/526 [==============================] - 0s 815us/step - loss: 0.0746 - accuracy: 0.9632 - val_loss: 3.5092 - val_accuracy: 0.6805\n",
      "Epoch 498/500\n",
      "526/526 [==============================] - 0s 823us/step - loss: 0.1178 - accuracy: 0.9559 - val_loss: 3.5560 - val_accuracy: 0.7013\n",
      "Epoch 499/500\n",
      "526/526 [==============================] - 0s 800us/step - loss: 0.0696 - accuracy: 0.9692 - val_loss: 3.3825 - val_accuracy: 0.6961\n",
      "Epoch 500/500\n",
      "526/526 [==============================] - 0s 810us/step - loss: 0.0794 - accuracy: 0.9616 - val_loss: 3.4226 - val_accuracy: 0.7299\n",
      "12/12 [==============================] - 0s 727us/step - loss: 3.7908 - accuracy: 0.7370\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(6,)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "\tkeras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "\tkeras.layers.Dense(3, activation=tf.nn.softmax),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history=model.fit(train_x2, train_y2, epochs=500,validation_data=(val_x, val_y), batch_size=6)\n",
    "\n",
    "predicted=model.predict(test_x)\n",
    "test_loss, test_acc = model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76eb7745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.1984397e-02, 9.7775912e-01, 2.5652896e-04],\n",
       "       [9.9985886e-01, 1.4114140e-04, 6.9307275e-11],\n",
       "       [9.9478143e-01, 5.2183769e-03, 1.3222488e-07],\n",
       "       ...,\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43669dae",
   "metadata": {},
   "source": [
    "# 예측 정확도를 계산하는 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "641dfa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "predicted_plot=[]\n",
    "correct_plot=[]\n",
    "\n",
    "count_array=[0 for j in range(3)]\n",
    "\n",
    "predicted_result=[0 for j in range(len(test_y))]\n",
    "for i in range(len(test_y)):\n",
    "    maxIndex=tf.argmax(predicted[i])\n",
    "    predicted_plot.append(maxIndex-1)\n",
    "    #     print(type(maxIndex.numpy().item()))\n",
    "    index=0\n",
    "    if(y_origin[i]==-1):\n",
    "        index=0 \n",
    "    elif y_origin[i]==0:\n",
    "        index=1\n",
    "    elif y_origin[i]==1:\n",
    "        index=2\n",
    "    predicted_result[i]=index-1\n",
    "    if index==maxIndex.numpy().item():\n",
    "        count=count+1\n",
    "        count_array[index]=count_array[index]+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1645a9e3",
   "metadata": {},
   "source": [
    "# 예측 정확도\n",
    "\n",
    "## 맞춘 개수 , 전체 개수 , 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a21b77af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263\n",
      "384\n",
      "0.6848958333333334\n"
     ]
    }
   ],
   "source": [
    "print(count)\n",
    "print(len(test_y))\n",
    "print(count/len(test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3743cd09",
   "metadata": {},
   "source": [
    "# 시각화하는 부분\n",
    "## -1(감소): 100, 0(유지): 355, 1(증가):23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69bafa30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label=['Decreasing','Maintain','Increasing']\n",
    "values=[count_array[0]/8*100,count_array[1]/355*100,count_array[2]/23*100]\n",
    "\n",
    "x = np.arange(3)\n",
    "\n",
    "plt.bar(x, values)\n",
    "plt.xticks(x, label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "450d9146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratio = [count,len(test_y)-count]\n",
    "labels = ['Correct', 'Wrong']\n",
    "\n",
    "plt.pie(ratio, labels=labels, autopct='%.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d1e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5fdf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
